{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3e81d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow_io import bigquery as tfio_bq"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44eef419",
   "metadata": {},
   "source": [
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('epochs', 1, 'Nubmer of epochs')\n",
    "flags.DEFINE_integer('units', 32, 'Number units in a hidden layer')\n",
    "flags.DEFINE_integer('per_replica_batch_size', 128, 'Per replica batch size')\n",
    "flags.DEFINE_float('dropout_ratio', 0.5, 'Dropout ratio')\n",
    "flags.DEFINE_string('training_table', 'jk-mlops-dev.chicago_taxi_ml.training', 'Training table name')\n",
    "flags.DEFINE_string('validation_table', 'jk-mlops-dev.chicago_taxi_ml.training', 'Validationa table name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32668546",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FLAGS:\n",
    "    epochs=1\n",
    "    units=32\n",
    "    per_replica_batch_size=128\n",
    "    dropout_ratio=0.5\n",
    "    training_table='jk-mlops-dev.chicago_taxi_ml.training'\n",
    "    validation_table='jk-mlops-dev.chicago_taxi_ml.training'\n",
    "    testing_table='jk-mlops-dev.chicago_taxi_ml.testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acfb0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_MODEL_DIR = '/tmp/saved_model'\n",
    "LOCAL_TB_DIR = '/tmp/logs'\n",
    "LOCAL_CHECKPOINT_DIR = '/tmp/checkpoints'\n",
    "EVALUATION_FILE_NAME = 'evaluations.json'\n",
    "\n",
    "FEATURES = {\n",
    "    \"tip_bin\": (\"categorical\", tf.int64),\n",
    "    \"trip_month\": (\"categorical\", tf.int64),\n",
    "    \"trip_day\": (\"categorical\", tf.int64),\n",
    "    \"trip_day_of_week\": (\"categorical\", tf.int64),\n",
    "    \"trip_hour\": (\"categorical\", tf.int64),\n",
    "    \"payment_type\": (\"categorical\", tf.string),\n",
    "    \"pickup_grid\": (\"categorical\", tf.string),\n",
    "    \"dropoff_grid\": (\"categorical\", tf.string),\n",
    "    \"euclidean\": (\"numeric\", tf.double),\n",
    "    \"trip_seconds\": (\"numeric\", tf.int64),\n",
    "    \"trip_miles\": (\"numeric\", tf.double),\n",
    "}\n",
    "\n",
    "TARGET_FEATURE_NAME = \"tip_bin\"\n",
    "TARGET_LABELS = [\"tip<20%\", \"tip>=20%\"]\n",
    "\n",
    "\n",
    "def set_job_dirs():\n",
    "    \"\"\"Sets job directories based on env variables set by Vertex AI.\"\"\"\n",
    "    \n",
    "    model_dir = os.getenv('AIP_MODEL_DIR', LOCAL_MODEL_DIR)\n",
    "    tb_dir = os.getenv('AIP_TENSORBOARD_LOG_DIR', LOCAL_TB_DIR)\n",
    "    checkpoint_dir = os.getenv('AIP_CHECKPOINT_DIR', LOCAL_CHECKPOINT_DIR)\n",
    "    \n",
    "    return model_dir, tb_dir, checkpoint_dir\n",
    "\n",
    "\n",
    "def get_bq_dataset(table_name, selected_fields, target_feature='tip_bin', batch_size=32):\n",
    "    \n",
    "    def _transform_row(row_dict):\n",
    "        trimmed_dict = {column:\n",
    "                       (tf.strings.strip(tensor) if tensor.dtype == 'string' else tensor) \n",
    "                       for (column,tensor) in row_dict.items()\n",
    "                       }\n",
    "        target = trimmed_dict.pop(target_feature)\n",
    "        return (trimmed_dict, target)\n",
    "\n",
    "    project_id, dataset_id, table_id = table_name.split('.')\n",
    "    \n",
    "    client = tfio_bq.BigQueryClient()\n",
    "    parent = f'projects/{project_id}'\n",
    "\n",
    "    read_session = client.read_session(\n",
    "        parent=parent,\n",
    "        project_id=project_id,\n",
    "        table_id=table_id,\n",
    "        dataset_id=dataset_id,\n",
    "        selected_fields=selected_fields,\n",
    "    )\n",
    "\n",
    "    dataset = read_session.parallel_read_rows().map(_transform_row).batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype):\n",
    "    \"\"\"Creates a CategoryEncoding layer for a given feature.\"\"\"\n",
    "\n",
    "    if dtype == tf.string:\n",
    "      index = preprocessing.StringLookup()\n",
    "    else:\n",
    "      index = preprocessing.IntegerLookup()\n",
    "\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    index.adapt(feature_ds)\n",
    "    encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "    return lambda feature: encoder(index(feature))\n",
    "\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "  \"\"\"\"Creates a Normalization layer for a given feature.\"\"\"\n",
    "  normalizer = preprocessing.Normalization()\n",
    "\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "\n",
    "def create_model(dataset, input_features, units, dropout_ratio):\n",
    "    \"\"\"Creates a binary classifier for Chicago Taxi tip prediction task.\"\"\"\n",
    "    \n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    for feature_name, feature_info in input_features.items():\n",
    "        col = tf.keras.Input(shape=(1,), name=feature_name, dtype=feature_info[1])\n",
    "        if feature_info[0] == 'categorical':\n",
    "            \n",
    "            encoding_layer = get_category_encoding_layer(feature_name, \n",
    "                                                         dataset,\n",
    "                                                         feature_info[1])\n",
    "        else:\n",
    "            encoding_layer = get_normalization_layer(feature_name,\n",
    "                                                     dataset) \n",
    "        encoded_col = encoding_layer(col)\n",
    "        all_inputs.append(col)\n",
    "        encoded_features.append(encoded_col)\n",
    "        \n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(units, activation=\"relu\")(all_features)\n",
    "    x = tf.keras.layers.Dropout(dropout_ratio)(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    del argv\n",
    "    \n",
    "    # Set distribution strategy\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    global_batch_size = (strategy.num_replicas_in_sync *\n",
    "                         FLAGS.per_replica_batch_size)\n",
    "    \n",
    "    # Prepare datasets\n",
    "    selected_fields = {key: {'output_type': value[1]} for key, value in FEATURES.items()}\n",
    "    validation_ds = get_bq_dataset(FLAGS.validation_table, \n",
    "                                   selected_fields, \n",
    "                                   batch_size=global_batch_size)\n",
    "    training_ds = get_bq_dataset(FLAGS.training_table,\n",
    "                                 selected_fields,\n",
    "                                 batch_size=global_batch_size)\n",
    "    \n",
    "    \n",
    "    # Prepare the model\n",
    "    input_features = {key: value for key, value in FEATURES.items() if key != TARGET_FEATURE_NAME}\n",
    "    logging.info('Creating the model ...')\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model(training_ds, input_features, FLAGS.units, FLAGS.dropout_ratio)\n",
    "        model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Configure Keras callbacks\n",
    "    model_dir, tb_dir, checkpoint_dir = set_job_dirs()\n",
    "    callbacks = [tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=checkpoint_dir)]\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=tb_dir, update_freq='batch'))\n",
    "    \n",
    "    logging.info('Starting training ...')\n",
    "    model.fit(training_ds, \n",
    "              epochs=FLAGS.epochs, \n",
    "              validation_data=validation_ds,\n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    # Save trained model\n",
    "    logging.info('Training completed. Saving the trained model to: {}'.format(model_dir))\n",
    "    model.save(model_dir, save_traces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1eb6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Creating the model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:absl:Starting training ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5515/5515 [==============================] - 114s 20ms/step - loss: 0.2811 - accuracy: 0.8661 - val_loss: 0.2591 - val_accuracy: 0.8856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Training completed. Saving the trained model to: /tmp/saved_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "logging.set_verbosity(logging.INFO)\n",
    "argv = []\n",
    "main(argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37626504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/saved_model'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOCAL_MODEL_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0974ef87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc7f407e320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc7f407e320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc7d45db290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc7d45db290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc7f40aa320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7fc7f40aa320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(LOCAL_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13311b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13dd88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b60928bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "global_batch_size = 32\n",
    "selected_fields = {key: {'output_type': value[1]} for key, value in FEATURES.items()}\n",
    "testing_ds = get_bq_dataset(FLAGS.testing_table,\n",
    "                                selected_fields,\n",
    "                                batch_size=global_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998a6f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3549/3549 [==============================] - 14s 4ms/step - loss: 0.2694 - accuracy: 0.8825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26938238739967346, 0.8825347423553467]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testing_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fefbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b87941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae3306ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import uuid\n",
    "import kfp\n",
    "import json\n",
    "\n",
    "import kfp.v2.dsl as dsl\n",
    "\n",
    "from datetime import datetime\n",
    "from google.cloud import aiplatform\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2 import compiler\n",
    "from kfp.v2.google.client import AIPlatformClient\n",
    "from kfp.v2.dsl import (Artifact, Dataset, Input, InputPath, Model, Output,\n",
    "                        OutputPath, Metrics, ClassificationMetrics)\n",
    "\n",
    "\n",
    "from typing import NamedTuple, List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bde51d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-workshop-bucket'\n",
    "REGION = 'us-central1'\n",
    "PIPELINES_SA = 'pipelines-sa@jk-mlops-dev.iam.gserviceaccount.com'\n",
    "\n",
    "BQ_DATASET_NAME = 'chicago_taxi_training_dataset' # Change to your BQ datasent name.\n",
    "BQ_TRAIN_SPLIT_NAME = 'train_split'\n",
    "BQ_VALID_SPLIT_NAME = 'valid_split'\n",
    "BQ_TEST_SPLIT_NAME = 'test_split'\n",
    "BQ_LOCATION = 'US'\n",
    "SAMPLE_SIZE = 1000000\n",
    "YEAR = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ab034ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_client = AIPlatformClient(\n",
    "    project_id=PROJECT,\n",
    "    region=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df92b36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #args = [\n",
    "    #            '--epochs=' + str(epochs), \n",
    "    #            '--per_replica_batch_size=' + str(per_replica_batch_size),\n",
    "    #            '--training_table=' + training_table,\n",
    "    #            '--validation_table=' + validation_table,\n",
    "    #        ],\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0e36bb97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[[\"--epochs=2\", \"--per_replica_batch_size=128\", \"--training_table=jk-mlops-dev.chicago_taxi_ml.training\", \"--validation_table=jk-mlops-dev.chicago_taxi_ml.validation\"]]'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_str = json.dumps(args)\n",
    "args_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c6b083f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--epochs=2',\n",
       " '--per_replica_batch_size=128',\n",
       " '--training_table=jk-mlops-dev.chicago_taxi_ml.training',\n",
       " '--validation_table=jk-mlops-dev.chicago_taxi_ml.validation']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9843b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0778bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_NAME = 'test-pipeline'\n",
    "\n",
    "training_container_image: str = 'gcr.io/jk-mlops-dev/taxi_classifier_trainer'\n",
    "serving_container_image: str = 'us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-4:latest'\n",
    "cmd = [\"python\", \"train.py\"]\n",
    "\n",
    "cmd = [\"python\", \"train.py\"]\n",
    "args = [\n",
    "    '--epochs=2', \n",
    "    '--per_replica_batch_size=128',\n",
    "    '--training_table=jk-mlops-dev.chicago_taxi_ml.training',\n",
    "    '--validation_table=jk-mlops-dev.chicago_taxi_ml.validation',\n",
    "]\n",
    "\n",
    "accelerator_count = 1\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "replica_count = 1\n",
    "machine_type = 'n1-standard-4'\n",
    "\n",
    "\n",
    "@dsl.pipeline(name=PIPELINE_NAME)\n",
    "def test_pipeline(\n",
    "    project: str,\n",
    "    location: str,\n",
    "#    model_display_name: str,\n",
    "    epochs: int,\n",
    "    per_replica_batch_size: int,\n",
    "    training_table: str,\n",
    "    validation_table: str,\n",
    "#    replica_count: int,\n",
    "#    machine_type: str,\n",
    "#    accelerator_count: int,\n",
    "#    accelerator_type: str\n",
    "):\n",
    "    \n",
    "    cmd = [\"python\", \"train.py\"]\n",
    "    args = [\n",
    "        '--epochs', str(epochs),\n",
    "        '--per_replica_batch_size', str(per_replica_batch_size),\n",
    "        '--training_table', str(training_table),\n",
    "        '--validation_table',  str(validation_table),\n",
    "    ]\n",
    "    \n",
    "    staging_bucket = 'gs://jk-vertex-workshop-bucket/test'\n",
    "    \n",
    "    train = gcc_aip.CustomContainerTrainingJobRunOp(\n",
    "        project=project,\n",
    "        location=location,\n",
    "        model_display_name=model_display_name,\n",
    "        display_name=model_display_name,\n",
    "        container_uri=training_container_image,\n",
    "        command = cmd,\n",
    "        args = args,\n",
    "        replica_count=replica_count,\n",
    "        machine_type=machine_type,\n",
    "        accelerator_type=accelerator_type,\n",
    "        accelerator_count=accelerator_count,\n",
    "        staging_bucket=staging_bucket,\n",
    "        model_serving_container_image_uri=serving_container_image\n",
    "    )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1a95cee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "package_path = 'test_pipeline.json'\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=test_pipeline,\n",
    "    package_path=package_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21bf92b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/test-pipeline-20210608204034?project=jk-mlops-dev\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline_root = f'{STAGING_BUCKET}/pipelines'\n",
    "model_display_name = 'Taxi tip predictor'\n",
    "\n",
    "schema = 'gs://jk-vertex-workshop-bucket/schema/schema.pbtxt'\n",
    "\n",
    "\n",
    "parameter_values = {\n",
    "    'project': PROJECT,\n",
    "    'location': REGION,\n",
    "    'epochs': 2,\n",
    "    'training_table': 'jk-mlops-dev.chicago_taxi_ml.training',\n",
    "    'validation_table': 'jk-mlops-dev.chicago_taxi_ml.validation',\n",
    "    'per_replica_batch_size': 128,\n",
    "#    'replica_count': 1,\n",
    "#    'machine_type': 'n1-standard-4',\n",
    "#    'accelerator_type': 'NVIDIA_TESLA_T4',\n",
    "#    'accelerator_count': 1\n",
    "}\n",
    "\n",
    "response = api_client.create_run_from_job_spec(\n",
    "    package_path,\n",
    "    pipeline_root=pipeline_root,\n",
    "    parameter_values=parameter_values,\n",
    "    enable_caching=False,\n",
    "    service_account=PIPELINES_SA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7fa5308d",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = {\n",
    "    \"tip_bin\": (\"categorical\", tf.int64),\n",
    "    \"trip_month\": (\"categorical\", tf.int64),\n",
    "    \"trip_day\": (\"categorical\", tf.int64),\n",
    "    \"trip_day_of_week\": (\"categorical\", tf.int64),\n",
    "    \"trip_hour\": (\"categorical\", tf.int64),\n",
    "    \"payment_type\": (\"categorical\", tf.string),\n",
    "    \"pickup_grid\": (\"categorical\", tf.string),\n",
    "    \"dropoff_grid\": (\"categorical\", tf.string),\n",
    "    \"euclidean\": (\"numeric\", tf.double),\n",
    "    \"trip_seconds\": (\"numeric\", tf.int64),\n",
    "    \"trip_miles\": (\"numeric\", tf.double),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6cb16668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tip_bin': {'output_type': tf.int64},\n",
       " 'trip_month': {'output_type': tf.int64},\n",
       " 'trip_day': {'output_type': tf.int64},\n",
       " 'trip_day_of_week': {'output_type': tf.int64},\n",
       " 'trip_hour': {'output_type': tf.int64},\n",
       " 'payment_type': {'output_type': tf.string},\n",
       " 'pickup_grid': {'output_type': tf.string},\n",
       " 'dropoff_grid': {'output_type': tf.string},\n",
       " 'euclidean': {'output_type': tf.float64},\n",
       " 'trip_seconds': {'output_type': tf.int64},\n",
       " 'trip_miles': {'output_type': tf.float64}}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key: {'output_type': value[1]} for key, value in FEATURES.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2e1d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "367e985f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-148-82b0cb1fbd90>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-148-82b0cb1fbd90>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for feature\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8bb1c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_data_validation as tfdv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6c47968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "STAGING_BUCKET = 'gs://jk-vertex-workshop-bucket'\n",
    "schema_file = os.path.join(STAGING_BUCKET, 'schema', 'schema.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "78754ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://jk-vertex-workshop-bucket/schema/schema.pbtxt\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls {schema_file}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ef148c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = tfdv.load_schema_text(schema_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8fbc9890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trip_month': {'output_type': tf.int64},\n",
       " 'trip_day': {'output_type': tf.int64},\n",
       " 'trip_day_of_week': {'output_type': tf.int64},\n",
       " 'trip_hour': {'output_type': tf.int64},\n",
       " 'trip_seconds': {'output_type': tf.int64},\n",
       " 'trip_miles': {'output_type': tf.float64},\n",
       " 'payment_type': {'output_type': tf.string},\n",
       " 'pickup_grid': {'output_type': tf.string},\n",
       " 'dropoff_grid': {'output_type': tf.string},\n",
       " 'euclidean': {'output_type': tf.float64},\n",
       " 'tip_bin': {'output_type': tf.int64}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCHEMA_TYPE_TO_TF_TYPE = {\n",
    "    1: tf.string,\n",
    "    2: tf.int64,\n",
    "    3: tf.double\n",
    "}\n",
    "\n",
    "{feature.name: {'output_type': SCHEMA_TYPE_TO_TF_TYPE[feature.type]} \n",
    " for feature in schema.feature if feature.type in SCHEMA_TYPE_TO_TF_TYPE.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0ff270ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trip_month': ('output_type', 2),\n",
       " 'trip_day': ('output_type', 2),\n",
       " 'trip_day_of_week': ('output_type', 2),\n",
       " 'trip_hour': ('output_type', 2),\n",
       " 'trip_seconds': ('output_type', 2),\n",
       " 'trip_miles': ('output_type', 3),\n",
       " 'payment_type': ('output_type', 1),\n",
       " 'pickup_grid': ('output_type', 1),\n",
       " 'dropoff_grid': ('output_type', 1),\n",
       " 'euclidean': ('output_type', 3)}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{feature.name: ('output_type', feature.type) \n",
    " for feature in schema.feature if feature.type in SCHEMA_TYPE_TO_TF_TYPE.keys() and feature.name != 'tip_bin'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "436694cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tip_bin'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_feature = None\n",
    "for feature in schema.feature:\n",
    "    if feature.HasField('annotation'):\n",
    "        if TARGET_TAG in feature.annotation.tag:\n",
    "            target_feature = feature.name\n",
    "target_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "ce036485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trip_month': ('categorical', tf.int64),\n",
       " 'trip_day': ('categorical', tf.int64),\n",
       " 'trip_day_of_week': ('categorical', tf.int64),\n",
       " 'trip_hour': ('categorical', tf.int64),\n",
       " 'trip_seconds': ('numeric', tf.int64),\n",
       " 'trip_miles': ('numeric', tf.float64),\n",
       " 'payment_type': ('categorical', tf.string),\n",
       " 'pickup_grid': ('categorical', tf.string),\n",
       " 'dropoff_grid': ('categorical', tf.string),\n",
       " 'euclidean': ('numeric', tf.float64),\n",
       " 'tip_bin': ('categorical', tf.int64)}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = {}\n",
    "for feature in schema.feature:\n",
    "    if feature.type == 2:\n",
    "        if feature.int_domain.is_categorical:\n",
    "            features[feature.name] = ('categorical', tf.int64)\n",
    "        else:\n",
    "            features[feature.name] = ('numeric', tf.int64)\n",
    "    elif feature.type == 1:\n",
    "        features[feature.name] = ('categorical', tf.string)\n",
    "    elif feature.type == 3:\n",
    "        features[feature.name] = ('numeric', tf.double)\n",
    "    \n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "068b793a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature {\n",
       "  name: \"trip_month\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    name: \"trip_month\"\n",
       "    min: 1\n",
       "    max: 12\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"trip_day\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    name: \"trip_day\"\n",
       "    min: 1\n",
       "    max: 31\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"trip_day_of_week\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    name: \"trip_day_of_week\"\n",
       "    min: 1\n",
       "    max: 7\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"trip_hour\"\n",
       "  type: INT\n",
       "  int_domain {\n",
       "    name: \"trip_hour\"\n",
       "    min: 0\n",
       "    max: 23\n",
       "    is_categorical: true\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"trip_seconds\"\n",
       "  type: INT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"trip_miles\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"payment_type\"\n",
       "  type: BYTES\n",
       "  domain: \"payment_type\"\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"pickup_grid\"\n",
       "  type: BYTES\n",
       "  domain: \"pickup_grid\"\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"dropoff_grid\"\n",
       "  type: BYTES\n",
       "  domain: \"dropoff_grid\"\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"euclidean\"\n",
       "  type: FLOAT\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "feature {\n",
       "  name: \"tip_bin\"\n",
       "  type: INT\n",
       "  bool_domain {\n",
       "  }\n",
       "  presence {\n",
       "    min_fraction: 1.0\n",
       "    min_count: 1\n",
       "  }\n",
       "  annotation {\n",
       "    tag: \"target\"\n",
       "  }\n",
       "  shape {\n",
       "    dim {\n",
       "      size: 1\n",
       "    }\n",
       "  }\n",
       "}\n",
       "string_domain {\n",
       "  name: \"payment_type\"\n",
       "  value: \"Cash\"\n",
       "  value: \"Credit Card\"\n",
       "  value: \"Dispute\"\n",
       "  value: \"Mobile\"\n",
       "  value: \"No Charge\"\n",
       "  value: \"Prcard\"\n",
       "  value: \"Prepaid\"\n",
       "  value: \"Unknown\"\n",
       "}\n",
       "string_domain {\n",
       "  name: \"pickup_grid\"\n",
       "  value: \"POINT(-87.5 41.7)\"\n",
       "  value: \"POINT(-87.6 41.7)\"\n",
       "  value: \"POINT(-87.6 41.8)\"\n",
       "  value: \"POINT(-87.6 41.9)\"\n",
       "  value: \"POINT(-87.6 42)\"\n",
       "  value: \"POINT(-87.7 41.7)\"\n",
       "  value: \"POINT(-87.7 41.8)\"\n",
       "  value: \"POINT(-87.7 41.9)\"\n",
       "  value: \"POINT(-87.7 42)\"\n",
       "  value: \"POINT(-87.8 41.8)\"\n",
       "  value: \"POINT(-87.8 41.9)\"\n",
       "  value: \"POINT(-87.8 42)\"\n",
       "  value: \"POINT(-87.9 42)\"\n",
       "}\n",
       "string_domain {\n",
       "  name: \"dropoff_grid\"\n",
       "  value: \"POINT(-87.5 41.7)\"\n",
       "  value: \"POINT(-87.6 41.7)\"\n",
       "  value: \"POINT(-87.6 41.8)\"\n",
       "  value: \"POINT(-87.6 41.9)\"\n",
       "  value: \"POINT(-87.6 42)\"\n",
       "  value: \"POINT(-87.7 41.7)\"\n",
       "  value: \"POINT(-87.7 41.8)\"\n",
       "  value: \"POINT(-87.7 41.9)\"\n",
       "  value: \"POINT(-87.7 42)\"\n",
       "  value: \"POINT(-87.8 41.8)\"\n",
       "  value: \"POINT(-87.8 41.9)\"\n",
       "  value: \"POINT(-87.8 42)\"\n",
       "  value: \"POINT(-87.9 42)\"\n",
       "}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b38c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
