{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4f75905",
   "metadata": {},
   "source": [
    "# Training and deploying a tabular model using Vertex custom training job\n",
    "\n",
    "![Training pipeline](../images/custom-tabular.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74349fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform_v1beta1 import types\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import exceptions\n",
    "\n",
    "from google.cloud.aiplatform.utils import JobClientWithOverride\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow_io import bigquery as tfio_bq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2677029",
   "metadata": {},
   "source": [
    "## Configure GCP settings\n",
    "\n",
    "*Before running the notebook make sure to follow the repo's README file to install the pre-requisites and configure GCP authentication.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b750f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-workshop-bucket'\n",
    "VERTEX_SA = 'vertex-sa@jk-mlops-dev.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8024f3a5",
   "metadata": {},
   "source": [
    "## Preparing training data in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c9105",
   "metadata": {},
   "source": [
    "### Explore Chicago Taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73baf337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1520.78query/s]\n",
      "Downloading: 100%|██████████| 3/3 [00:01<00:00,  2.61rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery data\n",
    "\n",
    "SELECT \n",
    "    *\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783520c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_key</th>\n",
       "      <td>d1c0e6541df70f7d76c58bd443cf911f038b7412</td>\n",
       "      <td>4155e838b1eecbc2a6634a90d1b639505ed9e19b</td>\n",
       "      <td>40228f36afe0c48983689c949d7e279ca8e8e9c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxi_id</th>\n",
       "      <td>fca0a720a85dda59406a7cb83b958b77c587e03c503c41...</td>\n",
       "      <td>487b08bac958b7e35025681d6ab2f21cd1e380f995fee0...</td>\n",
       "      <td>6fddf42c6f6cf22bcced14d3520b8218488737fe3d6212...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <td>2014-10-31 06:45:00+00:00</td>\n",
       "      <td>2019-12-22 08:45:00+00:00</td>\n",
       "      <td>2019-12-01 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <td>2014-10-31 07:00:00+00:00</td>\n",
       "      <td>2019-12-22 09:00:00+00:00</td>\n",
       "      <td>2019-12-01 20:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_seconds</th>\n",
       "      <td>780</td>\n",
       "      <td>1343</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_miles</th>\n",
       "      <td>3.4</td>\n",
       "      <td>17.61</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_community_area</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>10.65</td>\n",
       "      <td>43.5</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tips</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extras</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_total</th>\n",
       "      <td>12.65</td>\n",
       "      <td>43.5</td>\n",
       "      <td>6.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Cash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>None</td>\n",
       "      <td>Flash Cab</td>\n",
       "      <td>U Taxicab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_latitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_longitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_location</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_location</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        0  \\\n",
       "unique_key                       d1c0e6541df70f7d76c58bd443cf911f038b7412   \n",
       "taxi_id                 fca0a720a85dda59406a7cb83b958b77c587e03c503c41...   \n",
       "trip_start_timestamp                            2014-10-31 06:45:00+00:00   \n",
       "trip_end_timestamp                              2014-10-31 07:00:00+00:00   \n",
       "trip_seconds                                                          780   \n",
       "trip_miles                                                            3.4   \n",
       "pickup_census_tract                                                   NaN   \n",
       "dropoff_census_tract                                                  NaN   \n",
       "pickup_community_area                                                 NaN   \n",
       "dropoff_community_area                                                NaN   \n",
       "fare                                                                10.65   \n",
       "tips                                                                  2.0   \n",
       "tolls                                                                 0.0   \n",
       "extras                                                                0.0   \n",
       "trip_total                                                          12.65   \n",
       "payment_type                                                  Credit Card   \n",
       "company                                                              None   \n",
       "pickup_latitude                                                       NaN   \n",
       "pickup_longitude                                                      NaN   \n",
       "pickup_location                                                      None   \n",
       "dropoff_latitude                                                      NaN   \n",
       "dropoff_longitude                                                     NaN   \n",
       "dropoff_location                                                     None   \n",
       "\n",
       "                                                                        1  \\\n",
       "unique_key                       4155e838b1eecbc2a6634a90d1b639505ed9e19b   \n",
       "taxi_id                 487b08bac958b7e35025681d6ab2f21cd1e380f995fee0...   \n",
       "trip_start_timestamp                            2019-12-22 08:45:00+00:00   \n",
       "trip_end_timestamp                              2019-12-22 09:00:00+00:00   \n",
       "trip_seconds                                                         1343   \n",
       "trip_miles                                                          17.61   \n",
       "pickup_census_tract                                                   NaN   \n",
       "dropoff_census_tract                                                  NaN   \n",
       "pickup_community_area                                                 NaN   \n",
       "dropoff_community_area                                                NaN   \n",
       "fare                                                                 43.5   \n",
       "tips                                                                  0.0   \n",
       "tolls                                                                 0.0   \n",
       "extras                                                                0.0   \n",
       "trip_total                                                           43.5   \n",
       "payment_type                                                         Cash   \n",
       "company                                                         Flash Cab   \n",
       "pickup_latitude                                                       NaN   \n",
       "pickup_longitude                                                      NaN   \n",
       "pickup_location                                                      None   \n",
       "dropoff_latitude                                                      NaN   \n",
       "dropoff_longitude                                                     NaN   \n",
       "dropoff_location                                                     None   \n",
       "\n",
       "                                                                        2  \n",
       "unique_key                       40228f36afe0c48983689c949d7e279ca8e8e9c7  \n",
       "taxi_id                 6fddf42c6f6cf22bcced14d3520b8218488737fe3d6212...  \n",
       "trip_start_timestamp                            2019-12-01 20:00:00+00:00  \n",
       "trip_end_timestamp                              2019-12-01 20:00:00+00:00  \n",
       "trip_seconds                                                          420  \n",
       "trip_miles                                                            1.2  \n",
       "pickup_census_tract                                                   NaN  \n",
       "dropoff_census_tract                                                  NaN  \n",
       "pickup_community_area                                                 NaN  \n",
       "dropoff_community_area                                                NaN  \n",
       "fare                                                                 6.75  \n",
       "tips                                                                  0.0  \n",
       "tolls                                                                 0.0  \n",
       "extras                                                                0.0  \n",
       "trip_total                                                           6.75  \n",
       "payment_type                                                         Cash  \n",
       "company                                                         U Taxicab  \n",
       "pickup_latitude                                                       NaN  \n",
       "pickup_longitude                                                      NaN  \n",
       "pickup_location                                                      None  \n",
       "dropoff_latitude                                                      NaN  \n",
       "dropoff_longitude                                                     NaN  \n",
       "dropoff_location                                                     None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a540721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1221.40query/s]\n",
      "Downloading: 100%|██████████| 7/7 [00:01<00:00,  6.78rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery data\n",
    "\n",
    "SELECT \n",
    "    CAST(EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS string) AS trip_dayofweek, \n",
    "    FORMAT_DATE('%A',cast(trip_start_timestamp as date)) AS trip_dayname,\n",
    "    COUNT(*) as trip_count,\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "WHERE\n",
    "    EXTRACT(YEAR FROM trip_start_timestamp) = 2015 \n",
    "GROUP BY\n",
    "    trip_dayofweek,\n",
    "    trip_dayname\n",
    "ORDER BY\n",
    "    trip_dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfdbd538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_dayofweek</th>\n",
       "      <th>trip_dayname</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4141154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4378805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4542810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4918190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5289830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5009186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_dayofweek trip_dayname  trip_count\n",
       "0              1       Sunday     4141154\n",
       "1              2       Monday     4105900\n",
       "2              3      Tuesday     4378805\n",
       "3              4    Wednesday     4542810\n",
       "4              5     Thursday     4918190\n",
       "5              6       Friday     5289830\n",
       "6              7     Saturday     5009186"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65218a12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='trip_dayname'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(kind='bar', x='trip_dayname', y='trip_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25253d83",
   "metadata": {},
   "source": [
    "### Create  data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e465ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = 'chicago_taxi_training' # Change to your BQ datasent name.\n",
    "BQ_TABLE_NAME = 'chicago_trips'\n",
    "BQ_LOCATION = 'US'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b46498",
   "metadata": {},
   "source": [
    "#### Create a BQ dataset to host the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1205e7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset jk-mlops-dev.chicago_taxi_training already exists\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "\n",
    "dataset_id = f'{PROJECT}.{BQ_DATASET_NAME}'\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = BQ_LOCATION\n",
    "\n",
    "try:\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print('Created dataset: ', dataset_id)\n",
    "except exceptions.Conflict:\n",
    "    print('Dataset {} already exists'.format(dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efb9e1",
   "metadata": {},
   "source": [
    "#### Create a table with training features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1d4aa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7fd399d10910>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 1000000\n",
    "year = 2020\n",
    "\n",
    "sql_script_template = '''\n",
    "CREATE OR REPLACE TABLE `@PROJECT.@DATASET.@TABLE` \n",
    "AS (\n",
    "    WITH\n",
    "      taxitrips AS (\n",
    "      SELECT\n",
    "        FORMAT_DATETIME('%Y-%d-%m', trip_start_timestamp) AS date,\n",
    "        trip_start_timestamp,\n",
    "        trip_seconds,\n",
    "        trip_miles,\n",
    "        payment_type,\n",
    "        pickup_longitude,\n",
    "        pickup_latitude,\n",
    "        dropoff_longitude,\n",
    "        dropoff_latitude,\n",
    "        tips,\n",
    "        fare\n",
    "      FROM\n",
    "        `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "      WHERE 1=1 \n",
    "      AND pickup_longitude IS NOT NULL\n",
    "      AND pickup_latitude IS NOT NULL\n",
    "      AND dropoff_longitude IS NOT NULL\n",
    "      AND dropoff_latitude IS NOT NULL\n",
    "      AND trip_miles > 0\n",
    "      AND trip_seconds > 0\n",
    "      AND fare > 0\n",
    "      AND EXTRACT(YEAR FROM trip_start_timestamp) = @YEAR\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "      trip_start_timestamp,\n",
    "      EXTRACT(MONTH from trip_start_timestamp) as trip_month,\n",
    "      EXTRACT(DAY from trip_start_timestamp) as trip_day,\n",
    "      EXTRACT(DAYOFWEEK from trip_start_timestamp) as trip_day_of_week,\n",
    "      EXTRACT(HOUR from trip_start_timestamp) as trip_hour,\n",
    "      trip_seconds,\n",
    "      trip_miles,\n",
    "      payment_type,\n",
    "      ST_AsText(\n",
    "          ST_SnapToGrid(ST_GeogPoint(pickup_longitude, pickup_latitude), 0.1)\n",
    "      ) AS pickup_grid,\n",
    "      ST_AsText(\n",
    "          ST_SnapToGrid(ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0.1)\n",
    "      ) AS dropoff_grid,\n",
    "      ST_Distance(\n",
    "          ST_GeogPoint(pickup_longitude, pickup_latitude), \n",
    "          ST_GeogPoint(dropoff_longitude, dropoff_latitude)\n",
    "      ) AS euclidean,\n",
    "      IF((tips/fare >= 0.2), 1, 0) AS tip_bin,\n",
    "      CASE (ABS(MOD(FARM_FINGERPRINT(date),10))) \n",
    "          WHEN 9 THEN 'testing'\n",
    "          WHEN 8 THEN 'validation'\n",
    "          ELSE 'training' END AS data_split\n",
    "    FROM\n",
    "      taxitrips\n",
    "    LIMIT @LIMIT\n",
    ")\n",
    "'''\n",
    "\n",
    "sql_script = sql_script_template.replace(\n",
    "    '@PROJECT', PROJECT).replace(\n",
    "    '@DATASET', BQ_DATASET_NAME).replace(\n",
    "    '@TABLE', BQ_TABLE_NAME).replace(\n",
    "    '@YEAR', str(year)).replace(\n",
    "    '@LIMIT', str(sample_size))\n",
    "\n",
    "job = client.query(sql_script)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c8ab59",
   "metadata": {},
   "source": [
    "#### Review the created features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "382d12d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script = f'''\n",
    "SELECT * EXCEPT (trip_start_timestamp)\n",
    "FROM {PROJECT}.{BQ_DATASET_NAME}.{BQ_TABLE_NAME} \n",
    "'''\n",
    "df = client.query(sql_script).result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "353fb0fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trip_month</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_day</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_day_of_week</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_hour</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_seconds</th>\n",
       "      <td>240</td>\n",
       "      <td>1200</td>\n",
       "      <td>1780</td>\n",
       "      <td>660</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_miles</th>\n",
       "      <td>0.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>9.64</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>Cash</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Prcard</td>\n",
       "      <td>Cash</td>\n",
       "      <td>Unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_grid</th>\n",
       "      <td>POINT(-87.7 42)</td>\n",
       "      <td>POINT(-87.6 41.8)</td>\n",
       "      <td>POINT(-87.7 41.8)</td>\n",
       "      <td>POINT(-87.7 41.9)</td>\n",
       "      <td>POINT(-87.7 41.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_grid</th>\n",
       "      <td>POINT(-87.7 42)</td>\n",
       "      <td>POINT(-87.7 41.9)</td>\n",
       "      <td>POINT(-87.6 41.7)</td>\n",
       "      <td>POINT(-87.6 41.9)</td>\n",
       "      <td>POINT(-87.6 41.8)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>euclidean</th>\n",
       "      <td>2406.040979</td>\n",
       "      <td>2210.049904</td>\n",
       "      <td>12414.729032</td>\n",
       "      <td>3788.78383</td>\n",
       "      <td>10666.168995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tip_bin</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data_split</th>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                0                  1                  2  \\\n",
       "trip_month                      6                  6                  6   \n",
       "trip_day                       19                 19                 19   \n",
       "trip_day_of_week                6                  6                  6   \n",
       "trip_hour                       0                  0                  0   \n",
       "trip_seconds                  240               1200               1780   \n",
       "trip_miles                    0.9                4.1               9.64   \n",
       "payment_type                 Cash               Cash             Prcard   \n",
       "pickup_grid       POINT(-87.7 42)  POINT(-87.6 41.8)  POINT(-87.7 41.8)   \n",
       "dropoff_grid      POINT(-87.7 42)  POINT(-87.7 41.9)  POINT(-87.6 41.7)   \n",
       "euclidean             2406.040979        2210.049904       12414.729032   \n",
       "tip_bin                         0                  0                  0   \n",
       "data_split               training           training           training   \n",
       "\n",
       "                                  3                  4  \n",
       "trip_month                        6                  6  \n",
       "trip_day                         19                 19  \n",
       "trip_day_of_week                  6                  6  \n",
       "trip_hour                         0                  0  \n",
       "trip_seconds                    660                900  \n",
       "trip_miles                      1.1                0.4  \n",
       "payment_type                   Cash            Unknown  \n",
       "pickup_grid       POINT(-87.7 41.9)  POINT(-87.7 41.9)  \n",
       "dropoff_grid      POINT(-87.6 41.9)  POINT(-87.6 41.8)  \n",
       "euclidean                3788.78383       10666.168995  \n",
       "tip_bin                           0                  0  \n",
       "data_split                 training           training  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cbbcfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    635470\n",
       "1    364530\n",
       "Name: tip_bin, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tip_bin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a408fbb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "training      705807\n",
       "validation    180636\n",
       "testing       113557\n",
       "Name: data_split, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.data_split.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b425244",
   "metadata": {},
   "source": [
    "### Create training, validation, and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211314bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['training', 'validation', 'testing']\n",
    "\n",
    "sql_script_template = f'''\n",
    "CREATE OR REPLACE TABLE `@PROJECT.@DATASET.@VIEW`\n",
    "AS\n",
    "SELECT * EXCEPT (trip_start_timestamp, data_split)\n",
    "FROM `@PROJECT.@DATASET.@TABLE`\n",
    "WHERE data_split=\"@SPLIT\"\n",
    "'''\n",
    "\n",
    "for split in splits:\n",
    "    view_name = split + '_split'\n",
    "    sql_script = sql_script_template.replace(\n",
    "        '@PROJECT', PROJECT).replace(\n",
    "        '@DATASET', BQ_DATASET_NAME).replace(\n",
    "        '@TABLE', BQ_TABLE_NAME).replace(\n",
    "        '@VIEW', view_name).replace(\n",
    "        '@SPLIT', split)\n",
    "    job = client.query(sql_script)\n",
    "    job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a45430f",
   "metadata": {},
   "source": [
    "## Submitting Vertex training jobs\n",
    "\n",
    "### Prepare a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac07d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_FOLDER = 'trainer'\n",
    "if tf.io.gfile.exists(SCRIPT_FOLDER):\n",
    "    tf.io.gfile.rmtree(SCRIPT_FOLDER)\n",
    "tf.io.gfile.mkdir(SCRIPT_FOLDER)\n",
    "file_path = os.path.join(SCRIPT_FOLDER, 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d45aaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {file_path}\n",
    "\n",
    "\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow_io import bigquery as tfio_bq\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('epochs', 3, 'Nubmer of epochs')\n",
    "flags.DEFINE_integer('units', 32, 'Number units in a hidden layer')\n",
    "flags.DEFINE_integer('per_replica_batch_size', 128, 'Per replica batch size')\n",
    "flags.DEFINE_float('dropout_ratio', 0.5, 'Dropout ratio')\n",
    "flags.DEFINE_string('training_table', None, \"Training table name\")\n",
    "flags.DEFINE_string('validation_table', None, \"Validationa table name\")\n",
    "flags.mark_flag_as_required('training_table')\n",
    "flags.mark_flag_as_required('validation_table')\n",
    "\n",
    "LOCAL_MODEL_DIR = '/tmp/saved_model'\n",
    "LOCAL_TB_DIR = '/tmp/logs'\n",
    "LOCAL_CHECKPOINT_DIR = '/tmp/checkpoints'\n",
    "\n",
    "FEATURES = {\n",
    "    \"tip_bin\": (\"categorical\", tf.int64),\n",
    "    \"trip_month\": (\"categorical\", tf.int64),\n",
    "    \"trip_day\": (\"categorical\", tf.int64),\n",
    "    \"trip_day_of_week\": (\"categorical\", tf.int64),\n",
    "    \"trip_hour\": (\"categorical\", tf.int64),\n",
    "    \"payment_type\": (\"categorical\", tf.string),\n",
    "    \"pickup_grid\": (\"categorical\", tf.string),\n",
    "    \"dropoff_grid\": (\"categorical\", tf.string),\n",
    "    \"euclidean\": (\"numeric\", tf.double),\n",
    "    \"trip_seconds\": (\"numeric\", tf.int64),\n",
    "    \"trip_miles\": (\"numeric\", tf.double),\n",
    "}\n",
    "\n",
    "TARGET_FEATURE_NAME = \"tip_bin\"\n",
    "TARGET_LABELS = [\"tip<20%\", \"tip>=20%\"]\n",
    "\n",
    "\n",
    "def set_job_dirs():\n",
    "    \"\"\"Sets job directories based on env variables set by Vertex AI.\"\"\"\n",
    "    \n",
    "    model_dir = os.getenv('AIP_MODEL_DIR', LOCAL_MODEL_DIR)\n",
    "    tb_dir = os.getenv('AIP_TENSORBOARD_LOG_DIR', LOCAL_TB_DIR)\n",
    "    checkpoint_dir = os.getenv('AIP_CHECKPOINT_DIR', LOCAL_CHECKPOINT_DIR)\n",
    "    \n",
    "    return model_dir, tb_dir, checkpoint_dir\n",
    "\n",
    "\n",
    "def get_bq_dataset(table_name, selected_fields, target_feature='tip_bin', batch_size=32):\n",
    "    \n",
    "    def _transform_row(row_dict):\n",
    "        trimmed_dict = {column:\n",
    "                       (tf.strings.strip(tensor) if tensor.dtype == 'string' else tensor) \n",
    "                       for (column,tensor) in row_dict.items()\n",
    "                       }\n",
    "        target = trimmed_dict.pop(target_feature)\n",
    "        return (trimmed_dict, target)\n",
    "\n",
    "    project_id, dataset_id, table_id = table_name.split('.')\n",
    "    \n",
    "    client = tfio_bq.BigQueryClient()\n",
    "    parent = f'projects/{project_id}'\n",
    "\n",
    "    read_session = client.read_session(\n",
    "        parent=parent,\n",
    "        project_id=project_id,\n",
    "        table_id=table_id,\n",
    "        dataset_id=dataset_id,\n",
    "        selected_fields=selected_fields,\n",
    "    )\n",
    "\n",
    "    dataset = read_session.parallel_read_rows().map(_transform_row).batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype):\n",
    "    \"\"\"Creates a CategoryEncoding layer for a given feature.\"\"\"\n",
    "\n",
    "    if dtype == tf.string:\n",
    "      index = preprocessing.StringLookup()\n",
    "    else:\n",
    "      index = preprocessing.IntegerLookup()\n",
    "\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    index.adapt(feature_ds)\n",
    "    encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "    return lambda feature: encoder(index(feature))\n",
    "\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "  \"\"\"\"Creates a Normalization layer for a given feature.\"\"\"\n",
    "  normalizer = preprocessing.Normalization()\n",
    "\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "\n",
    "def create_model(dataset, input_features, units, dropout_ratio):\n",
    "    \"\"\"Creates a binary classifier for Chicago Taxi tip prediction task.\"\"\"\n",
    "    \n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    for feature_name, feature_info in input_features.items():\n",
    "        col = tf.keras.Input(shape=(1,), name=feature_name, dtype=feature_info[1])\n",
    "        if feature_info[0] == 'categorical':\n",
    "            \n",
    "            encoding_layer = get_category_encoding_layer(feature_name, \n",
    "                                                         dataset,\n",
    "                                                         feature_info[1])\n",
    "        else:\n",
    "            encoding_layer = get_normalization_layer(feature_name,\n",
    "                                                     dataset) \n",
    "        encoded_col = encoding_layer(col)\n",
    "        all_inputs.append(col)\n",
    "        encoded_features.append(encoded_col)\n",
    "        \n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(units, activation=\"relu\")(all_features)\n",
    "    x = tf.keras.layers.Dropout(dropout_ratio)(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    del argv\n",
    "    \n",
    "    # Set distribution strategy\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    global_batch_size = (strategy.num_replicas_in_sync *\n",
    "                         FLAGS.per_replica_batch_size)\n",
    "    \n",
    "    # Prepare datasets\n",
    "    selected_fields = {key: {'output_type': value[1]} for key, value in FEATURES.items()}\n",
    "    validation_ds = get_bq_dataset(FLAGS.validation_table, \n",
    "                                   selected_fields, \n",
    "                                   batch_size=global_batch_size)\n",
    "    training_ds = get_bq_dataset(FLAGS.training_table,\n",
    "                                 selected_fields,\n",
    "                                 batch_size=global_batch_size)\n",
    "    \n",
    "    # Prepare the model\n",
    "    input_features = {key: value for key, value in FEATURES.items() if key != TARGET_FEATURE_NAME}\n",
    "    logging.info('Creating the model ...')\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model(training_ds, input_features, FLAGS.units, FLAGS.dropout_ratio)\n",
    "        model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Configure Keras callbacks\n",
    "    model_dir, tb_dir, checkpoint_dir = set_job_dirs()\n",
    "    callbacks = [tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=checkpoint_dir)]\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=tb_dir, update_freq='batch'))\n",
    "    \n",
    "    logging.info('Starting training ...')\n",
    "    model.fit(training_ds, \n",
    "              epochs=FLAGS.epochs, \n",
    "              validation_data=validation_ds,\n",
    "              callbacks=callbacks)\n",
    "\n",
    "       # Save trained model\n",
    "    logging.info('Training completed. Saving the trained model to: {}'.format(model_dir))\n",
    "    model.save(model_dir)  \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd6a78c",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7b276c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f6acd9",
   "metadata": {},
   "source": [
    "### Create or set Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c9b17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing Tensorboard: projects/895222332033/locations/us-central1/tensorboards/7964545572260544512\n"
     ]
    }
   ],
   "source": [
    "tb_client = api_client = vertex_ai.initializer.global_config.create_client(\n",
    "        client_class=vertex_ai.utils.TensorboardClientWithOverride, location_override=REGION\n",
    ")\n",
    "parent = f'projects/{PROJECT}/locations/{REGION}'\n",
    "\n",
    "tensorboard_display_name = 'Workshop Tensorboard'\n",
    "tensorboard_ref = None\n",
    "\n",
    "for tensorboard in tb_client.list_tensorboards(parent=parent):\n",
    "    if tensorboard.display_name == tensorboard_display_name:\n",
    "        tensorboard_ref = tensorboard\n",
    "        \n",
    "if not tensorboard_ref:\n",
    "    print('Creating new Tensorboard')\n",
    "    tb_specs = types.Tensorboard(\n",
    "        display_name=tensorboard_display_name,\n",
    "        description=tensorboard_display_name\n",
    "    )\n",
    "    operation = tb_client.create_tensorboard(parent=parent, tensorboard=tb_specs)\n",
    "    tensorboard_ref = operation.result()\n",
    "else:\n",
    "    print('Using existing Tensorboard:', tensorboard_ref.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff28d5",
   "metadata": {},
   "source": [
    "### Configure and submit a custom Vertex job using a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc7df793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.source_utils:Training script copied to:\n",
      "gs://jk-vertex-workshop-bucket/JOB_20210605_144141/aiplatform-2021-06-05-14:41:42.176-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/703269627358085120\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/703269627358085120')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/703269627358085120?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/703269627358085120 current state:\n",
      "JobState.JOB_STATE_QUEUED\n"
     ]
    }
   ],
   "source": [
    "job_name = job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{STAGING_BUCKET}/jobs/{job_name}'\n",
    "\n",
    "container_uri = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "requirements = ['tensorflow-datasets==4.3.0']\n",
    "args = [\n",
    "    '--epochs=3', \n",
    "    '--per_replica_batch_size=128',\n",
    "    '--training_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.training_split',\n",
    "    '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.validation_split',\n",
    "    \n",
    "]\n",
    "\n",
    "machine_type = 'n1-standard-4'\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "accelerator_count = 1\n",
    "\n",
    "job = vertex_ai.CustomJob.from_local_script(\n",
    "    display_name=job_name,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    script_path='trainer/train.py',\n",
    "    container_uri=container_uri,\n",
    "    requirements=requirements,\n",
    "    args=args,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{job_name}'\n",
    ")\n",
    "\n",
    "job.run(sync=False, \n",
    "        service_account=VERTEX_SA,\n",
    "        tensorboard=tensorboard_ref.name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842d1a2",
   "metadata": {},
   "source": [
    "### Configure and submit a Vertex job using a custom container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506df88e",
   "metadata": {},
   "source": [
    "#### Create a docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aa691ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "TRAIN_IMAGE = f'gcr.io/{PROJECT}/taxi_classifier_trainer'\n",
    "\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"-c\", \"print('Hello')\"]\n",
    "'''\n",
    "\n",
    "with open(os.path.join(SCRIPT_FOLDER, 'Dockerfile'), 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b76872",
   "metadata": {},
   "source": [
    "#### Build a container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f8951e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 7.1 KiB before compression.\n",
      "Uploading tarball of [trainer] to [gs://jk-mlops-dev_cloudbuild/source/1622904117.191385-e34006d14df64fd5ad736e8d4f2029ab.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jk-mlops-dev/locations/global/builds/8bb57e16-e2a9-49af-9857-9fdca4c258d1].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/8bb57e16-e2a9-49af-9857-9fdca4c258d1?project=895222332033].\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/703269627358085120 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"8bb57e16-e2a9-49af-9857-9fdca4c258d1\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jk-mlops-dev_cloudbuild/source/1622904117.191385-e34006d14df64fd5ad736e8d4f2029ab.tgz#1622904117456277\n",
      "Copying gs://jk-mlops-dev_cloudbuild/source/1622904117.191385-e34006d14df64fd5ad736e8d4f2029ab.tgz#1622904117456277...\n",
      "/ [1 files][  2.7 KiB/  2.7 KiB]                                                \n",
      "Operation completed over 1 objects/2.7 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  9.728kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-5\n",
      "latest: Pulling from deeplearning-platform-release/tf2-gpu.2-5\n",
      "6e0aa5e7af40: Pulling fs layer\n",
      "d47239a868b3: Pulling fs layer\n",
      "49cbb10cca85: Pulling fs layer\n",
      "4450dd082e0f: Pulling fs layer\n",
      "2c645f69b1d6: Pulling fs layer\n",
      "c51f99ae46a1: Pulling fs layer\n",
      "4450dd082e0f: Waiting\n",
      "2c645f69b1d6: Waiting\n",
      "ece22f1f3a5c: Pulling fs layer\n",
      "0ecbf0b7bbf8: Pulling fs layer\n",
      "5848f1cb3b81: Pulling fs layer\n",
      "2f54b1f16acd: Pulling fs layer\n",
      "16e84ce81d85: Pulling fs layer\n",
      "c8e5550a4fa4: Pulling fs layer\n",
      "2e3325ceca25: Pulling fs layer\n",
      "184fc506e44a: Pulling fs layer\n",
      "4c311d4b2a10: Pulling fs layer\n",
      "c51f99ae46a1: Waiting\n",
      "116fdb019315: Pulling fs layer\n",
      "aeff92ad872e: Pulling fs layer\n",
      "c9952ed3db5f: Pulling fs layer\n",
      "fb3902b5a3a7: Pulling fs layer\n",
      "1f8b60f00749: Pulling fs layer\n",
      "d3ab4706459e: Pulling fs layer\n",
      "341ba8f946a1: Pulling fs layer\n",
      "79a0842bd8ff: Pulling fs layer\n",
      "e124988c5196: Pulling fs layer\n",
      "066a3d03cb12: Pulling fs layer\n",
      "cd55345c1107: Pulling fs layer\n",
      "4b14047dd86b: Pulling fs layer\n",
      "2e6bc3c78abb: Pulling fs layer\n",
      "ec905b2f50fb: Pulling fs layer\n",
      "bebe0539490e: Pulling fs layer\n",
      "cc5c7d8065a0: Pulling fs layer\n",
      "2e23073eebf2: Pulling fs layer\n",
      "ece22f1f3a5c: Waiting\n",
      "16e84ce81d85: Waiting\n",
      "0ecbf0b7bbf8: Waiting\n",
      "c8e5550a4fa4: Waiting\n",
      "5848f1cb3b81: Waiting\n",
      "2f54b1f16acd: Waiting\n",
      "2e3325ceca25: Waiting\n",
      "184fc506e44a: Waiting\n",
      "4c311d4b2a10: Waiting\n",
      "116fdb019315: Waiting\n",
      "aeff92ad872e: Waiting\n",
      "c9952ed3db5f: Waiting\n",
      "fb3902b5a3a7: Waiting\n",
      "1f8b60f00749: Waiting\n",
      "d3ab4706459e: Waiting\n",
      "341ba8f946a1: Waiting\n",
      "79a0842bd8ff: Waiting\n",
      "e124988c5196: Waiting\n",
      "066a3d03cb12: Waiting\n",
      "cd55345c1107: Waiting\n",
      "4b14047dd86b: Waiting\n",
      "2e6bc3c78abb: Waiting\n",
      "ec905b2f50fb: Waiting\n",
      "bebe0539490e: Waiting\n",
      "cc5c7d8065a0: Waiting\n",
      "2e23073eebf2: Waiting\n",
      "49cbb10cca85: Verifying Checksum\n",
      "49cbb10cca85: Download complete\n",
      "d47239a868b3: Verifying Checksum\n",
      "d47239a868b3: Download complete\n",
      "4450dd082e0f: Verifying Checksum\n",
      "4450dd082e0f: Download complete\n",
      "6e0aa5e7af40: Verifying Checksum\n",
      "6e0aa5e7af40: Download complete\n",
      "2c645f69b1d6: Verifying Checksum\n",
      "2c645f69b1d6: Download complete\n",
      "c51f99ae46a1: Verifying Checksum\n",
      "c51f99ae46a1: Download complete\n",
      "ece22f1f3a5c: Verifying Checksum\n",
      "ece22f1f3a5c: Download complete\n",
      "5848f1cb3b81: Verifying Checksum\n",
      "5848f1cb3b81: Download complete\n",
      "16e84ce81d85: Verifying Checksum\n",
      "16e84ce81d85: Download complete\n",
      "6e0aa5e7af40: Pull complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/703269627358085120 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "d47239a868b3: Pull complete\n",
      "49cbb10cca85: Pull complete\n",
      "4450dd082e0f: Pull complete\n",
      "2c645f69b1d6: Pull complete\n",
      "c51f99ae46a1: Pull complete\n",
      "ece22f1f3a5c: Pull complete\n",
      "2f54b1f16acd: Verifying Checksum\n",
      "2f54b1f16acd: Download complete\n",
      "2e3325ceca25: Verifying Checksum\n",
      "2e3325ceca25: Download complete\n",
      "0ecbf0b7bbf8: Verifying Checksum\n",
      "0ecbf0b7bbf8: Download complete\n",
      "c8e5550a4fa4: Verifying Checksum\n",
      "c8e5550a4fa4: Download complete\n",
      "116fdb019315: Download complete\n",
      "aeff92ad872e: Download complete\n",
      "184fc506e44a: Verifying Checksum\n",
      "184fc506e44a: Download complete\n",
      "fb3902b5a3a7: Verifying Checksum\n",
      "fb3902b5a3a7: Download complete\n",
      "1f8b60f00749: Verifying Checksum\n",
      "1f8b60f00749: Download complete\n",
      "4c311d4b2a10: Verifying Checksum\n",
      "4c311d4b2a10: Download complete\n",
      "d3ab4706459e: Verifying Checksum\n",
      "d3ab4706459e: Download complete\n",
      "341ba8f946a1: Verifying Checksum\n",
      "341ba8f946a1: Download complete\n",
      "79a0842bd8ff: Verifying Checksum\n",
      "79a0842bd8ff: Download complete\n",
      "e124988c5196: Verifying Checksum\n",
      "e124988c5196: Download complete\n",
      "066a3d03cb12: Verifying Checksum\n",
      "066a3d03cb12: Download complete\n",
      "cd55345c1107: Verifying Checksum\n",
      "cd55345c1107: Download complete\n",
      "c9952ed3db5f: Verifying Checksum\n",
      "c9952ed3db5f: Download complete\n",
      "ec905b2f50fb: Verifying Checksum\n",
      "ec905b2f50fb: Download complete\n",
      "4b14047dd86b: Verifying Checksum\n",
      "4b14047dd86b: Download complete\n",
      "cc5c7d8065a0: Verifying Checksum\n",
      "cc5c7d8065a0: Download complete\n",
      "2e23073eebf2: Verifying Checksum\n",
      "2e23073eebf2: Download complete\n",
      "bebe0539490e: Verifying Checksum\n",
      "bebe0539490e: Download complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/703269627358085120 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "2e6bc3c78abb: Verifying Checksum\n",
      "2e6bc3c78abb: Download complete\n",
      "0ecbf0b7bbf8: Pull complete\n",
      "5848f1cb3b81: Pull complete\n",
      "2f54b1f16acd: Pull complete\n",
      "16e84ce81d85: Pull complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/703269627358085120 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "c8e5550a4fa4: Pull complete\n",
      "2e3325ceca25: Pull complete\n",
      "184fc506e44a: Pull complete\n",
      "4c311d4b2a10: Pull complete\n",
      "116fdb019315: Pull complete\n",
      "aeff92ad872e: Pull complete\n",
      "c9952ed3db5f: Pull complete\n",
      "fb3902b5a3a7: Pull complete\n",
      "1f8b60f00749: Pull complete\n",
      "d3ab4706459e: Pull complete\n",
      "341ba8f946a1: Pull complete\n",
      "79a0842bd8ff: Pull complete\n",
      "e124988c5196: Pull complete\n",
      "066a3d03cb12: Pull complete\n",
      "cd55345c1107: Pull complete\n",
      "4b14047dd86b: Pull complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/703269627358085120 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "2e6bc3c78abb: Pull complete\n",
      "ec905b2f50fb: Pull complete\n",
      "bebe0539490e: Pull complete\n",
      "cc5c7d8065a0: Pull complete\n",
      "2e23073eebf2: Pull complete\n",
      "Digest: sha256:d04d79d10f652dd4333d50e077cb736e19416f6aa334f9ee823a5a0b201fd92b\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-gpu.2-5:latest\n",
      " ---> 950969e5619c\n",
      "Step 2/5 : WORKDIR /trainer\n",
      " ---> Running in ef6649d67b2f\n",
      "Removing intermediate container ef6649d67b2f\n",
      " ---> 49639dffedd4\n",
      "Step 3/5 : COPY train.py .\n",
      " ---> 9b2f042d2993\n",
      "Step 4/5 : ENTRYPOINT [\"python\"]\n",
      " ---> Running in 67a62192f69b\n",
      "Removing intermediate container 67a62192f69b\n",
      " ---> 42f75330ed84\n",
      "Step 5/5 : CMD [\"-c\", \"print('Hello')\"]\n",
      " ---> Running in 3fed3042d707\n",
      "Removing intermediate container 3fed3042d707\n",
      " ---> 465e03b6fab9\n",
      "Successfully built 465e03b6fab9\n",
      "Successfully tagged gcr.io/jk-mlops-dev/taxi_classifier_trainer:latest\n",
      "PUSH\n",
      "Pushing gcr.io/jk-mlops-dev/taxi_classifier_trainer\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/taxi_classifier_trainer]\n",
      "add757f09884: Preparing\n",
      "38ac87f4b7b7: Preparing\n",
      "5bfc464d3f17: Preparing\n",
      "006edaea14d2: Preparing\n",
      "622db28de254: Preparing\n",
      "e97052e30556: Preparing\n",
      "35c8fc085027: Preparing\n",
      "43677d90a58d: Preparing\n",
      "db84285b3362: Preparing\n",
      "786c0730cb59: Preparing\n",
      "a27f18de1f93: Preparing\n",
      "fca7d1dfb5d0: Preparing\n",
      "058d686f5924: Preparing\n",
      "90f85de2196f: Preparing\n",
      "801e383a0e80: Preparing\n",
      "1c86eaf882b2: Preparing\n",
      "b24d2519572d: Preparing\n",
      "160dfbfba824: Preparing\n",
      "efaea8806df6: Preparing\n",
      "36292a1c8291: Preparing\n",
      "d569b49af22b: Preparing\n",
      "186cb363f69f: Preparing\n",
      "d5de0a9a6a11: Preparing\n",
      "75867e8b38e6: Preparing\n",
      "edb28f196cf4: Preparing\n",
      "463a01dbc7de: Preparing\n",
      "716331d2d72b: Preparing\n",
      "c79fa966f459: Preparing\n",
      "64d8b9e63cdf: Preparing\n",
      "988749f5bf51: Preparing\n",
      "2d4faa2fa9fe: Preparing\n",
      "6f15325cc380: Preparing\n",
      "1e77dd81f9fa: Preparing\n",
      "030309cad0ba: Preparing\n",
      "36292a1c8291: Waiting\n",
      "d569b49af22b: Waiting\n",
      "186cb363f69f: Waiting\n",
      "d5de0a9a6a11: Waiting\n",
      "e97052e30556: Waiting\n",
      "35c8fc085027: Waiting\n",
      "43677d90a58d: Waiting\n",
      "db84285b3362: Waiting\n",
      "786c0730cb59: Waiting\n",
      "a27f18de1f93: Waiting\n",
      "fca7d1dfb5d0: Waiting\n",
      "058d686f5924: Waiting\n",
      "90f85de2196f: Waiting\n",
      "801e383a0e80: Waiting\n",
      "1c86eaf882b2: Waiting\n",
      "b24d2519572d: Waiting\n",
      "160dfbfba824: Waiting\n",
      "efaea8806df6: Waiting\n",
      "75867e8b38e6: Waiting\n",
      "edb28f196cf4: Waiting\n",
      "463a01dbc7de: Waiting\n",
      "716331d2d72b: Waiting\n",
      "c79fa966f459: Waiting\n",
      "64d8b9e63cdf: Waiting\n",
      "988749f5bf51: Waiting\n",
      "2d4faa2fa9fe: Waiting\n",
      "6f15325cc380: Waiting\n",
      "1e77dd81f9fa: Waiting\n",
      "030309cad0ba: Waiting\n",
      "006edaea14d2: Layer already exists\n",
      "622db28de254: Layer already exists\n",
      "5bfc464d3f17: Layer already exists\n",
      "e97052e30556: Layer already exists\n",
      "35c8fc085027: Layer already exists\n",
      "43677d90a58d: Layer already exists\n",
      "db84285b3362: Layer already exists\n",
      "786c0730cb59: Layer already exists\n",
      "a27f18de1f93: Layer already exists\n",
      "fca7d1dfb5d0: Layer already exists\n",
      "058d686f5924: Layer already exists\n",
      "90f85de2196f: Layer already exists\n",
      "801e383a0e80: Layer already exists\n",
      "b24d2519572d: Layer already exists\n",
      "1c86eaf882b2: Layer already exists\n",
      "160dfbfba824: Layer already exists\n",
      "efaea8806df6: Layer already exists\n",
      "36292a1c8291: Layer already exists\n",
      "d5de0a9a6a11: Layer already exists\n",
      "186cb363f69f: Layer already exists\n",
      "d569b49af22b: Layer already exists\n",
      "75867e8b38e6: Layer already exists\n",
      "463a01dbc7de: Layer already exists\n",
      "edb28f196cf4: Layer already exists\n",
      "716331d2d72b: Layer already exists\n",
      "c79fa966f459: Layer already exists\n",
      "64d8b9e63cdf: Layer already exists\n",
      "988749f5bf51: Layer already exists\n",
      "2d4faa2fa9fe: Layer already exists\n",
      "6f15325cc380: Layer already exists\n",
      "1e77dd81f9fa: Layer already exists\n",
      "030309cad0ba: Layer already exists\n",
      "38ac87f4b7b7: Pushed\n",
      "add757f09884: Pushed\n",
      "latest: digest: sha256:7d5093961a84b85ad435b609bb92ed7468973f6cddd1b674c2db509d02ab198f size: 7455\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                      IMAGES                                                 STATUS\n",
      "8bb57e16-e2a9-49af-9857-9fdca4c258d1  2021-06-05T14:41:57+00:00  6M52S     gs://jk-mlops-dev_cloudbuild/source/1622904117.191385-e34006d14df64fd5ad736e8d4f2029ab.tgz  gcr.io/jk-mlops-dev/taxi_classifier_trainer (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag {TRAIN_IMAGE} {SCRIPT_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d419b2",
   "metadata": {},
   "source": [
    "#### Prepare worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42abfb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_IMAGE,\n",
    "            \"command\": [\"python\", \"train.py\"],\n",
    "            \"args\": [\n",
    "                '--epochs=2', \n",
    "                '--per_replica_batch_size=128',\n",
    "                '--training_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.training_split',\n",
    "                '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.validation_split',\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb60210",
   "metadata": {},
   "source": [
    "#### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c650c445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/5254720000769392640\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/5254720000769392640')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/5254720000769392640?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5254720000769392640 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5254720000769392640 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5254720000769392640 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/2120214660119527424 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{job_name}'\n",
    ")\n",
    "\n",
    "job.run(sync=False, \n",
    "        service_account=VERTEX_SA,\n",
    "        tensorboard=tensorboard_ref.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab73ec2",
   "metadata": {},
   "source": [
    "### Configure and submit a hyperparameter job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1224c9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = \"HYPER_JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "hyperparameter_tuning_job_spec = {\n",
    "        \"display_name\": job_name,\n",
    "        \"max_trial_count\": 6,\n",
    "        \"parallel_trial_count\": 2,\n",
    "        \"max_failed_trial_count\": 1,\n",
    "        \"study_spec\": {\n",
    "            \"metrics\": [\n",
    "                {\n",
    "                    \"metric_id\": \"accuracy\",\n",
    "                    \"goal\": vertex_ai.gapic.StudySpec.MetricSpec.GoalType.MAXIMIZE,\n",
    "                }\n",
    "            ],\n",
    "            \"parameters\": [\n",
    "                {\n",
    "                    \"parameter_id\": \"units\",\n",
    "                    \"discrete_value_spec\": {\"values\": [32, 64]},\n",
    "                },\n",
    "                {\n",
    "                    \"parameter_id\": \"dropout_ratio\",\n",
    "                    \"double_value_spec\": {\"min_value\": 0.4, \"max_value\": 0.6},\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"trial_job_spec\": {\n",
    "            \"base_output_directory\": {\n",
    "                \"output_uri_prefix\": f\"{STAGING_BUCKET}/{job_name}\"\n",
    "            },\n",
    "            \"worker_pool_specs\": [\n",
    "                {\n",
    "                    \"machine_spec\": {\n",
    "                        \"machine_type\": \"n1-standard-4\",\n",
    "                        \"accelerator_type\": vertex_ai.gapic.AcceleratorType.NVIDIA_TESLA_T4,\n",
    "                        \"accelerator_count\": 1,\n",
    "                    },\n",
    "                    \"replica_count\": 1,\n",
    "                    \"container_spec\": {\n",
    "                        \"image_uri\": TRAIN_IMAGE,\n",
    "                        \"command\": [\"python\", \"train.py\"],\n",
    "                        \"args\": [\n",
    "                            '--epochs=2', \n",
    "                            '--per_replica_batch_size=128',\n",
    "                            '--training_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.training_split',\n",
    "                            '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.validation_split',\n",
    "                        ],\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5e4c08e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response: name: \"projects/895222332033/locations/us-central1/hyperparameterTuningJobs/6331080311710941184\"\n",
      "display_name: \"HYPER_JOB_20210605_154300\"\n",
      "study_spec {\n",
      "  metrics {\n",
      "    metric_id: \"accuracy\"\n",
      "    goal: MAXIMIZE\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"units\"\n",
      "    discrete_value_spec {\n",
      "      values: 32.0\n",
      "      values: 64.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"dropout_ratio\"\n",
      "    double_value_spec {\n",
      "      min_value: 0.4\n",
      "      max_value: 0.6\n",
      "    }\n",
      "  }\n",
      "}\n",
      "max_trial_count: 6\n",
      "parallel_trial_count: 2\n",
      "max_failed_trial_count: 1\n",
      "trial_job_spec {\n",
      "  worker_pool_specs {\n",
      "    machine_spec {\n",
      "      machine_type: \"n1-standard-4\"\n",
      "      accelerator_type: NVIDIA_TESLA_T4\n",
      "      accelerator_count: 1\n",
      "    }\n",
      "    replica_count: 1\n",
      "    disk_spec {\n",
      "      boot_disk_type: \"pd-ssd\"\n",
      "      boot_disk_size_gb: 100\n",
      "    }\n",
      "    container_spec {\n",
      "      image_uri: \"gcr.io/jk-mlops-dev/taxi_classifier_trainer\"\n",
      "      command: \"python\"\n",
      "      command: \"train.py\"\n",
      "      args: \"--epochs=2\"\n",
      "      args: \"--per_replica_batch_size=128\"\n",
      "      args: \"--training_table=jk-mlops-dev.chicago_taxi_training.training_split\"\n",
      "      args: \"--validation_table=jk-mlops-dev.chicago_taxi_training.validation_split\"\n",
      "    }\n",
      "  }\n",
      "  base_output_directory {\n",
      "    output_uri_prefix: \"gs://jk-vertex-workshop-bucket/HYPER_JOB_20210605_154300\"\n",
      "  }\n",
      "}\n",
      "state: JOB_STATE_PENDING\n",
      "create_time {\n",
      "  seconds: 1622907781\n",
      "  nanos: 868565000\n",
      "}\n",
      "update_time {\n",
      "  seconds: 1622907781\n",
      "  nanos: 868565000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "job_client = api_client = vertex_ai.initializer.global_config.create_client(\n",
    "        client_class=JobClientWithOverride, location_override=REGION\n",
    ")\n",
    "\n",
    "parent = f'projects/{PROJECT}/locations/{REGION}'\n",
    "\n",
    "response = job_client.create_hyperparameter_tuning_job(\n",
    "    parent=parent, hyperparameter_tuning_job=hyperparameter_tuning_job_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb85ff6",
   "metadata": {},
   "source": [
    "### Monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ac942fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "job_spec = job_client.get_hyperparameter_tuning_job(\n",
    "    name = response.name\n",
    ")\n",
    "print(job_spec.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484b6919",
   "metadata": {},
   "source": [
    "## Deploying a model to Vertex "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5c41dd",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5eae2530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-05 16:36:49.836264: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "The given SavedModel SignatureDef contains the following input(s):\n",
      "  inputs['dropoff_grid'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_dropoff_grid:0\n",
      "  inputs['euclidean'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_euclidean:0\n",
      "  inputs['payment_type'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_payment_type:0\n",
      "  inputs['pickup_grid'] tensor_info:\n",
      "      dtype: DT_STRING\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_pickup_grid:0\n",
      "  inputs['trip_day'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_trip_day:0\n",
      "  inputs['trip_day_of_week'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_trip_day_of_week:0\n",
      "  inputs['trip_hour'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_trip_hour:0\n",
      "  inputs['trip_miles'] tensor_info:\n",
      "      dtype: DT_DOUBLE\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_trip_miles:0\n",
      "  inputs['trip_month'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_trip_month:0\n",
      "  inputs['trip_seconds'] tensor_info:\n",
      "      dtype: DT_INT64\n",
      "      shape: (-1, 1)\n",
      "      name: serving_default_trip_seconds:0\n",
      "The given SavedModel SignatureDef contains the following output(s):\n",
      "  outputs['dense_1'] tensor_info:\n",
      "      dtype: DT_FLOAT\n",
      "      shape: (-1, 1)\n",
      "      name: StatefulPartitionedCall:0\n",
      "Method name is: tensorflow/serving/predict\n"
     ]
    }
   ],
   "source": [
    "saved_model_path = 'gs://jk-vertex-workshop-bucket/models/taxi'\n",
    "\n",
    "!saved_model_cli show --dir {saved_model_path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfba892",
   "metadata": {},
   "source": [
    "### Upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a705515a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/895222332033/locations/us-central1/models/1209225296042000384/operations/623572901408276480\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/895222332033/locations/us-central1/models/1209225296042000384\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/895222332033/locations/us-central1/models/1209225296042000384')\n"
     ]
    }
   ],
   "source": [
    "display_name = 'taxi-tip-classifier'\n",
    "serving_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-4:latest'\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "    display_name=display_name,\n",
    "    artifact_uri=saved_model_path,\n",
    "    serving_container_image_uri=serving_image_uri\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5bbdcf",
   "metadata": {},
   "source": [
    "### Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ef1337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/895222332033/locations/us-central1/endpoints/5073920706744418304/operations/7716742314516807680\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/895222332033/locations/us-central1/endpoints/5073920706744418304')\n"
     ]
    }
   ],
   "source": [
    "display_name = 'taxi-endpoint'\n",
    "\n",
    "endpoint = vertex_ai.Endpoint.create(display_name=display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26d241",
   "metadata": {},
   "source": [
    "### Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7848952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/895222332033/locations/us-central1/endpoints/5073920706744418304/operations/7564745827093053440\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n"
     ]
    }
   ],
   "source": [
    "deployed_model_display_name = 'taxi-v1'\n",
    "traffic_percentage = 100\n",
    "machine_type = 'n1-standard-4'\n",
    "\n",
    "endpoint = model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=deployed_model_display_name,\n",
    "        machine_type=machine_type,\n",
    "        traffic_percentage=traffic_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d800f3",
   "metadata": {},
   "source": [
    "## Invoking the deployed model using Vertex SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb217a7",
   "metadata": {},
   "source": [
    "### Get the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6987cf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.cloud.aiplatform.models.Endpoint object at 0x7fd434bb1fd0> \n",
      "resource name: projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n"
     ]
    }
   ],
   "source": [
    "for endpoint_info in vertex_ai.Endpoint.list(filter='display_name=\"taxi-endpoint\"'):\n",
    "    print(endpoint_info)\n",
    "    \n",
    "endpoint = vertex_ai.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea2cb9",
   "metadata": {},
   "source": [
    "### Call the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3114e19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of tip > 20%: [[0.75511366]]\n"
     ]
    }
   ],
   "source": [
    "test_instances = [  \n",
    "    \n",
    "    {\n",
    "        \"dropoff_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"euclidean\": [2064.2696],\n",
    "        \"payment_type\": [\"Credit Card\"],\n",
    "        \"pickup_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"trip_miles\": [1.37],\n",
    "        \"trip_day\": [12],\n",
    "        \"trip_hour\": [16],\n",
    "        \"trip_month\": [2],\n",
    "        \"trip_day_of_week\": [4],\n",
    "        \"trip_seconds\": [555]\n",
    "    }\n",
    "]\n",
    "\n",
    "predictions = endpoint.predict(instances=test_instances)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "print('Probability of tip > 20%:', prob.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b174e6de",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8032325",
   "metadata": {},
   "source": [
    "### Undeploy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d4525a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[id: \"6844468678998622208\"\n",
       "model: \"projects/895222332033/locations/us-central1/models/1209225296042000384\"\n",
       "display_name: \"taxi-v1\"\n",
       "create_time {\n",
       "  seconds: 1622911488\n",
       "  nanos: 953563000\n",
       "}\n",
       "dedicated_resources {\n",
       "  machine_spec {\n",
       "    machine_type: \"n1-standard-4\"\n",
       "  }\n",
       "  min_replica_count: 1\n",
       "  max_replica_count: 1\n",
       "}\n",
       "]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "82b6e3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Undeploying Endpoint model: projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n",
      "INFO:google.cloud.aiplatform.models:Undeploy Endpoint model backing LRO: projects/895222332033/locations/us-central1/endpoints/5073920706744418304/operations/2301163762603786240\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model undeployed. Resource name: projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<google.cloud.aiplatform.models.Endpoint object at 0x7fd399c3d750> \n",
       "resource name: projects/895222332033/locations/us-central1/endpoints/5073920706744418304"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d4f185",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "763e7c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.base:Deleting Endpoint : projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n",
      "INFO:google.cloud.aiplatform.base:Delete Endpoint  backing LRO: projects/895222332033/locations/us-central1/operations/2247120567075340288\n",
      "INFO:google.cloud.aiplatform.base:Endpoint deleted. . Resource name: projects/895222332033/locations/us-central1/endpoints/5073920706744418304\n"
     ]
    }
   ],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db248f6a",
   "metadata": {},
   "source": [
    "### Delete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "432b4ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.base:Deleting Model : projects/895222332033/locations/us-central1/models/1209225296042000384\n",
      "INFO:google.cloud.aiplatform.base:Delete Model  backing LRO: projects/895222332033/locations/us-central1/operations/3316725478575833088\n",
      "INFO:google.cloud.aiplatform.base:Model deleted. . Resource name: projects/895222332033/locations/us-central1/models/1209225296042000384\n"
     ]
    }
   ],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9cea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
