{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9e5ed3a",
   "metadata": {},
   "source": [
    "# Training and deploying a tabular model using Vertex custom training job\n",
    "\n",
    "![Training pipeline](../images/custom-tabular.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c2ee530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform_v1beta1 import types\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import exceptions\n",
    "\n",
    "from google.cloud.aiplatform.utils import JobClientWithOverride\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow_io import bigquery as tfio_bq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7f49e8",
   "metadata": {},
   "source": [
    "## Configure GCP settings\n",
    "\n",
    "*Before running the notebook make sure to follow the repo's README file to install the pre-requisites and configure GCP authentication.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc6ce93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "STAGING_BUCKET = 'gs://jk-vertex-workshop-bucket'\n",
    "VERTEX_SA = 'vertex-sa@jk-mlops-dev.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ed0f64",
   "metadata": {},
   "source": [
    "## Preparing training data in BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf68515",
   "metadata": {},
   "source": [
    "### Explore Chicago Taxi dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2bb4fa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1197.00query/s]\n",
      "Downloading: 100%|██████████| 3/3 [00:01<00:00,  2.70rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery data\n",
    "\n",
    "SELECT \n",
    "    *\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "LIMIT 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c5b0934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>unique_key</th>\n",
       "      <td>6b85442c881e411f57c3ef4a2d4f7249d8420dfb</td>\n",
       "      <td>2d9c5d734a9cce3ce46165cf5daec179966575f7</td>\n",
       "      <td>dac8c12a16f2cf4fe2b05ea31f920f9890f3ddb6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>taxi_id</th>\n",
       "      <td>247904284efdcb2650dee9d02e4109af8c1dd7e36e87fd...</td>\n",
       "      <td>247904284efdcb2650dee9d02e4109af8c1dd7e36e87fd...</td>\n",
       "      <td>247904284efdcb2650dee9d02e4109af8c1dd7e36e87fd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_start_timestamp</th>\n",
       "      <td>2018-05-15 08:45:00+00:00</td>\n",
       "      <td>2018-05-15 09:45:00+00:00</td>\n",
       "      <td>2018-05-15 10:30:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_end_timestamp</th>\n",
       "      <td>2018-05-15 09:45:00+00:00</td>\n",
       "      <td>2018-05-15 10:00:00+00:00</td>\n",
       "      <td>2018-05-15 11:00:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_seconds</th>\n",
       "      <td>3380</td>\n",
       "      <td>763</td>\n",
       "      <td>1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_miles</th>\n",
       "      <td>17.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>17.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_census_tract</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_census_tract</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_community_area</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_community_area</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>45.25</td>\n",
       "      <td>10.5</td>\n",
       "      <td>42.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tips</th>\n",
       "      <td>12.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolls</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extras</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trip_total</th>\n",
       "      <td>62.19</td>\n",
       "      <td>14.0</td>\n",
       "      <td>51.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>payment_type</th>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Credit Card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>Taxi Affiliation Service Yellow</td>\n",
       "      <td>Taxi Affiliation Service Yellow</td>\n",
       "      <td>Taxi Affiliation Service Yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_latitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_longitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pickup_location</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_location</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        0  \\\n",
       "unique_key                       6b85442c881e411f57c3ef4a2d4f7249d8420dfb   \n",
       "taxi_id                 247904284efdcb2650dee9d02e4109af8c1dd7e36e87fd...   \n",
       "trip_start_timestamp                            2018-05-15 08:45:00+00:00   \n",
       "trip_end_timestamp                              2018-05-15 09:45:00+00:00   \n",
       "trip_seconds                                                         3380   \n",
       "trip_miles                                                           17.4   \n",
       "pickup_census_tract                                                   NaN   \n",
       "dropoff_census_tract                                                  NaN   \n",
       "pickup_community_area                                                 NaN   \n",
       "dropoff_community_area                                                NaN   \n",
       "fare                                                                45.25   \n",
       "tips                                                                12.44   \n",
       "tolls                                                                 0.0   \n",
       "extras                                                                4.0   \n",
       "trip_total                                                          62.19   \n",
       "payment_type                                                  Credit Card   \n",
       "company                                   Taxi Affiliation Service Yellow   \n",
       "pickup_latitude                                                       NaN   \n",
       "pickup_longitude                                                      NaN   \n",
       "pickup_location                                                      None   \n",
       "dropoff_latitude                                                      NaN   \n",
       "dropoff_longitude                                                     NaN   \n",
       "dropoff_location                                                     None   \n",
       "\n",
       "                                                                        1  \\\n",
       "unique_key                       2d9c5d734a9cce3ce46165cf5daec179966575f7   \n",
       "taxi_id                 247904284efdcb2650dee9d02e4109af8c1dd7e36e87fd...   \n",
       "trip_start_timestamp                            2018-05-15 09:45:00+00:00   \n",
       "trip_end_timestamp                              2018-05-15 10:00:00+00:00   \n",
       "trip_seconds                                                          763   \n",
       "trip_miles                                                            2.5   \n",
       "pickup_census_tract                                                   NaN   \n",
       "dropoff_census_tract                                                  NaN   \n",
       "pickup_community_area                                                 NaN   \n",
       "dropoff_community_area                                                NaN   \n",
       "fare                                                                 10.5   \n",
       "tips                                                                  3.0   \n",
       "tolls                                                                 0.0   \n",
       "extras                                                                0.0   \n",
       "trip_total                                                           14.0   \n",
       "payment_type                                                  Credit Card   \n",
       "company                                   Taxi Affiliation Service Yellow   \n",
       "pickup_latitude                                                       NaN   \n",
       "pickup_longitude                                                      NaN   \n",
       "pickup_location                                                      None   \n",
       "dropoff_latitude                                                      NaN   \n",
       "dropoff_longitude                                                     NaN   \n",
       "dropoff_location                                                     None   \n",
       "\n",
       "                                                                        2  \n",
       "unique_key                       dac8c12a16f2cf4fe2b05ea31f920f9890f3ddb6  \n",
       "taxi_id                 247904284efdcb2650dee9d02e4109af8c1dd7e36e87fd...  \n",
       "trip_start_timestamp                            2018-05-15 10:30:00+00:00  \n",
       "trip_end_timestamp                              2018-05-15 11:00:00+00:00  \n",
       "trip_seconds                                                         1614  \n",
       "trip_miles                                                           17.4  \n",
       "pickup_census_tract                                                   NaN  \n",
       "dropoff_census_tract                                                  NaN  \n",
       "pickup_community_area                                                 NaN  \n",
       "dropoff_community_area                                                NaN  \n",
       "fare                                                                42.25  \n",
       "tips                                                                 8.55  \n",
       "tolls                                                                 0.0  \n",
       "extras                                                                0.0  \n",
       "trip_total                                                           51.3  \n",
       "payment_type                                                  Credit Card  \n",
       "company                                   Taxi Affiliation Service Yellow  \n",
       "pickup_latitude                                                       NaN  \n",
       "pickup_longitude                                                      NaN  \n",
       "pickup_location                                                      None  \n",
       "dropoff_latitude                                                      NaN  \n",
       "dropoff_longitude                                                     NaN  \n",
       "dropoff_location                                                     None  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "54330b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 1337.47query/s]\n",
      "Downloading: 100%|██████████| 7/7 [00:01<00:00,  6.55rows/s]\n"
     ]
    }
   ],
   "source": [
    "%%bigquery data\n",
    "\n",
    "SELECT \n",
    "    CAST(EXTRACT(DAYOFWEEK FROM trip_start_timestamp) AS string) AS trip_dayofweek, \n",
    "    FORMAT_DATE('%A',cast(trip_start_timestamp as date)) AS trip_dayname,\n",
    "    COUNT(*) as trip_count,\n",
    "FROM `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "WHERE\n",
    "    EXTRACT(YEAR FROM trip_start_timestamp) = 2015 \n",
    "GROUP BY\n",
    "    trip_dayofweek,\n",
    "    trip_dayname\n",
    "ORDER BY\n",
    "    trip_dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "340a1b76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_dayofweek</th>\n",
       "      <th>trip_dayname</th>\n",
       "      <th>trip_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>4141154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>4105900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>4378805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>4542810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>4918190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Friday</td>\n",
       "      <td>5289830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>5009186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  trip_dayofweek trip_dayname  trip_count\n",
       "0              1       Sunday     4141154\n",
       "1              2       Monday     4105900\n",
       "2              3      Tuesday     4378805\n",
       "3              4    Wednesday     4542810\n",
       "4              5     Thursday     4918190\n",
       "5              6       Friday     5289830\n",
       "6              7     Saturday     5009186"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7384e321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='trip_dayname'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data.plot(kind='bar', x='trip_dayname', y='trip_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d3db1",
   "metadata": {},
   "source": [
    "### Create  data splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a4c160b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_DATASET_NAME = 'chicago_taxi_training_dataset' # Change to your BQ datasent name.\n",
    "BQ_TRAIN_SPLIT_NAME = 'train_split'\n",
    "BQ_VALID_SPLIT_NAME = 'valid_split'\n",
    "BQ_TEST_SPLIT_NAME = 'test_split'\n",
    "BQ_LOCATION = 'US'\n",
    "SAMPLE_SIZE = 1000000\n",
    "YEAR = 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e489f4d4",
   "metadata": {},
   "source": [
    "#### Create a BQ dataset to host the splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df3b812e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset:  jk-mlops-dev.chicago_taxi_training_dataset\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "\n",
    "dataset_id = f'{PROJECT}.{BQ_DATASET_NAME}'\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "dataset.location = BQ_LOCATION\n",
    "\n",
    "try:\n",
    "    dataset = client.create_dataset(dataset, timeout=30)\n",
    "    print('Created dataset: ', dataset_id)\n",
    "except exceptions.Conflict:\n",
    "    print('Dataset {} already exists'.format(dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d0a9c",
   "metadata": {},
   "source": [
    "#### Create training, validation, and test splits tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d860892",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_script_template = '''\n",
    "CREATE TEMP TABLE features \n",
    "AS (\n",
    "    WITH\n",
    "      taxitrips AS (\n",
    "      SELECT\n",
    "        FORMAT_DATETIME('%Y-%d-%m', trip_start_timestamp) AS date,\n",
    "        trip_start_timestamp,\n",
    "        trip_seconds,\n",
    "        trip_miles,\n",
    "        payment_type,\n",
    "        pickup_longitude,\n",
    "        pickup_latitude,\n",
    "        dropoff_longitude,\n",
    "        dropoff_latitude,\n",
    "        tips,\n",
    "        fare\n",
    "      FROM\n",
    "        `bigquery-public-data.chicago_taxi_trips.taxi_trips`\n",
    "      WHERE 1=1 \n",
    "      AND pickup_longitude IS NOT NULL\n",
    "      AND pickup_latitude IS NOT NULL\n",
    "      AND dropoff_longitude IS NOT NULL\n",
    "      AND dropoff_latitude IS NOT NULL\n",
    "      AND trip_miles > 0\n",
    "      AND trip_seconds > 0\n",
    "      AND fare > 0\n",
    "      AND EXTRACT(YEAR FROM trip_start_timestamp) = @YEAR\n",
    "    )\n",
    "\n",
    "    SELECT\n",
    "      trip_start_timestamp,\n",
    "      EXTRACT(MONTH from trip_start_timestamp) as trip_month,\n",
    "      EXTRACT(DAY from trip_start_timestamp) as trip_day,\n",
    "      EXTRACT(DAYOFWEEK from trip_start_timestamp) as trip_day_of_week,\n",
    "      EXTRACT(HOUR from trip_start_timestamp) as trip_hour,\n",
    "      trip_seconds,\n",
    "      trip_miles,\n",
    "      payment_type,\n",
    "      ST_AsText(\n",
    "          ST_SnapToGrid(ST_GeogPoint(pickup_longitude, pickup_latitude), 0.1)\n",
    "      ) AS pickup_grid,\n",
    "      ST_AsText(\n",
    "          ST_SnapToGrid(ST_GeogPoint(dropoff_longitude, dropoff_latitude), 0.1)\n",
    "      ) AS dropoff_grid,\n",
    "      ST_Distance(\n",
    "          ST_GeogPoint(pickup_longitude, pickup_latitude), \n",
    "          ST_GeogPoint(dropoff_longitude, dropoff_latitude)\n",
    "      ) AS euclidean,\n",
    "      IF((tips/fare >= 0.2), 1, 0) AS tip_bin,\n",
    "      CASE (ABS(MOD(FARM_FINGERPRINT(date),10))) \n",
    "          WHEN 9 THEN 'TEST'\n",
    "          WHEN 8 THEN 'VALIDATE'\n",
    "          ELSE 'TRAIN' END AS data_split\n",
    "    FROM\n",
    "      taxitrips\n",
    "    LIMIT @LIMIT\n",
    ");\n",
    "\n",
    "CREATE OR REPLACE TABLE `@PROJECT.@DATASET.@TRAIN_SPLIT`\n",
    "AS\n",
    "SELECT * EXCEPT (trip_start_timestamp, data_split)\n",
    "FROM features\n",
    "WHERE data_split='TRAIN';\n",
    "\n",
    "CREATE OR REPLACE TABLE `@PROJECT.@DATASET.@VALIDATE_SPLIT`\n",
    "AS\n",
    "SELECT * EXCEPT (trip_start_timestamp, data_split)\n",
    "FROM features\n",
    "WHERE data_split='VALIDATE';\n",
    "\n",
    "CREATE OR REPLACE TABLE `@PROJECT.@DATASET.@TEST_SPLIT`\n",
    "AS\n",
    "SELECT * EXCEPT (trip_start_timestamp, data_split)\n",
    "FROM features\n",
    "WHERE data_split='TEST';\n",
    "\n",
    "DROP TABLE features;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17c62b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f7845dfbfd0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_script = sql_script_template.replace(\n",
    "    '@PROJECT', PROJECT).replace(\n",
    "    '@DATASET', BQ_DATASET_NAME).replace(\n",
    "    '@TRAIN_SPLIT', BQ_TRAIN_SPLIT_NAME).replace(\n",
    "    '@VALIDATE_SPLIT', BQ_VALID_SPLIT_NAME).replace(\n",
    "    '@TEST_SPLIT', BQ_TEST_SPLIT_NAME).replace(\n",
    "    '@YEAR', str(YEAR)).replace(\n",
    "    '@LIMIT', str(SAMPLE_SIZE))\n",
    "\n",
    "job = client.query(sql_script)\n",
    "job.result()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d8282",
   "metadata": {},
   "source": [
    "## Submitting Vertex training jobs\n",
    "\n",
    "### Prepare a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "863fafd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_FOLDER = 'trainer'\n",
    "if tf.io.gfile.exists(SCRIPT_FOLDER):\n",
    "    tf.io.gfile.rmtree(SCRIPT_FOLDER)\n",
    "tf.io.gfile.mkdir(SCRIPT_FOLDER)\n",
    "file_path = os.path.join(SCRIPT_FOLDER, 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27316d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {file_path}\n",
    "\n",
    "\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import json\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "from absl import logging\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow_io import bigquery as tfio_bq\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('epochs', 3, 'Nubmer of epochs')\n",
    "flags.DEFINE_integer('units', 32, 'Number units in a hidden layer')\n",
    "flags.DEFINE_integer('per_replica_batch_size', 128, 'Per replica batch size')\n",
    "flags.DEFINE_float('dropout_ratio', 0.5, 'Dropout ratio')\n",
    "flags.DEFINE_string('training_table', None, 'Training table name')\n",
    "flags.DEFINE_string('validation_table', None, 'Validationa table name')\n",
    "flags.DEFINE_string('testing_table', None, 'Testing table name')\n",
    "flags.mark_flag_as_required('training_table')\n",
    "flags.mark_flag_as_required('validation_table')\n",
    "flags.mark_flag_as_required('testing_table')\n",
    "\n",
    "LOCAL_MODEL_DIR = '/tmp/saved_model'\n",
    "LOCAL_TB_DIR = '/tmp/logs'\n",
    "LOCAL_CHECKPOINT_DIR = '/tmp/checkpoints'\n",
    "EVALUATION_FILE_NAME = 'evaluations.json'\n",
    "\n",
    "FEATURES = {\n",
    "    \"tip_bin\": (\"categorical\", tf.int64),\n",
    "    \"trip_month\": (\"categorical\", tf.int64),\n",
    "    \"trip_day\": (\"categorical\", tf.int64),\n",
    "    \"trip_day_of_week\": (\"categorical\", tf.int64),\n",
    "    \"trip_hour\": (\"categorical\", tf.int64),\n",
    "    \"payment_type\": (\"categorical\", tf.string),\n",
    "    \"pickup_grid\": (\"categorical\", tf.string),\n",
    "    \"dropoff_grid\": (\"categorical\", tf.string),\n",
    "    \"euclidean\": (\"numeric\", tf.double),\n",
    "    \"trip_seconds\": (\"numeric\", tf.int64),\n",
    "    \"trip_miles\": (\"numeric\", tf.double),\n",
    "}\n",
    "\n",
    "TARGET_FEATURE_NAME = \"tip_bin\"\n",
    "TARGET_LABELS = [\"tip<20%\", \"tip>=20%\"]\n",
    "\n",
    "\n",
    "def set_job_dirs():\n",
    "    \"\"\"Sets job directories based on env variables set by Vertex AI.\"\"\"\n",
    "    \n",
    "    model_dir = os.getenv('AIP_MODEL_DIR', LOCAL_MODEL_DIR)\n",
    "    tb_dir = os.getenv('AIP_TENSORBOARD_LOG_DIR', LOCAL_TB_DIR)\n",
    "    checkpoint_dir = os.getenv('AIP_CHECKPOINT_DIR', LOCAL_CHECKPOINT_DIR)\n",
    "    \n",
    "    return model_dir, tb_dir, checkpoint_dir\n",
    "\n",
    "\n",
    "def get_bq_dataset(table_name, selected_fields, target_feature='tip_bin', batch_size=32):\n",
    "    \n",
    "    def _transform_row(row_dict):\n",
    "        trimmed_dict = {column:\n",
    "                       (tf.strings.strip(tensor) if tensor.dtype == 'string' else tensor) \n",
    "                       for (column,tensor) in row_dict.items()\n",
    "                       }\n",
    "        target = trimmed_dict.pop(target_feature)\n",
    "        return (trimmed_dict, target)\n",
    "\n",
    "    project_id, dataset_id, table_id = table_name.split('.')\n",
    "    \n",
    "    client = tfio_bq.BigQueryClient()\n",
    "    parent = f'projects/{project_id}'\n",
    "\n",
    "    read_session = client.read_session(\n",
    "        parent=parent,\n",
    "        project_id=project_id,\n",
    "        table_id=table_id,\n",
    "        dataset_id=dataset_id,\n",
    "        selected_fields=selected_fields,\n",
    "    )\n",
    "\n",
    "    dataset = read_session.parallel_read_rows().map(_transform_row).batch(batch_size)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_category_encoding_layer(name, dataset, dtype):\n",
    "    \"\"\"Creates a CategoryEncoding layer for a given feature.\"\"\"\n",
    "\n",
    "    if dtype == tf.string:\n",
    "      index = preprocessing.StringLookup()\n",
    "    else:\n",
    "      index = preprocessing.IntegerLookup()\n",
    "\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    index.adapt(feature_ds)\n",
    "    encoder = preprocessing.CategoryEncoding(max_tokens=index.vocab_size())\n",
    "\n",
    "    return lambda feature: encoder(index(feature))\n",
    "\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "  \"\"\"\"Creates a Normalization layer for a given feature.\"\"\"\n",
    "  normalizer = preprocessing.Normalization()\n",
    "\n",
    "  feature_ds = dataset.map(lambda x, y: x[name])\n",
    "  normalizer.adapt(feature_ds)\n",
    "\n",
    "  return normalizer\n",
    "\n",
    "\n",
    "def create_model(dataset, input_features, units, dropout_ratio):\n",
    "    \"\"\"Creates a binary classifier for Chicago Taxi tip prediction task.\"\"\"\n",
    "    \n",
    "    all_inputs = []\n",
    "    encoded_features = []\n",
    "    for feature_name, feature_info in input_features.items():\n",
    "        col = tf.keras.Input(shape=(1,), name=feature_name, dtype=feature_info[1])\n",
    "        if feature_info[0] == 'categorical':\n",
    "            \n",
    "            encoding_layer = get_category_encoding_layer(feature_name, \n",
    "                                                         dataset,\n",
    "                                                         feature_info[1])\n",
    "        else:\n",
    "            encoding_layer = get_normalization_layer(feature_name,\n",
    "                                                     dataset) \n",
    "        encoded_col = encoding_layer(col)\n",
    "        all_inputs.append(col)\n",
    "        encoded_features.append(encoded_col)\n",
    "        \n",
    "    all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(units, activation=\"relu\")(all_features)\n",
    "    x = tf.keras.layers.Dropout(dropout_ratio)(x)\n",
    "    output = tf.keras.layers.Dense(1)(x)\n",
    "    model = tf.keras.Model(all_inputs, output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    del argv\n",
    "    \n",
    "    # Set distribution strategy\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    \n",
    "    global_batch_size = (strategy.num_replicas_in_sync *\n",
    "                         FLAGS.per_replica_batch_size)\n",
    "    \n",
    "    # Prepare datasets\n",
    "    selected_fields = {key: {'output_type': value[1]} for key, value in FEATURES.items()}\n",
    "    validation_ds = get_bq_dataset(FLAGS.validation_table, \n",
    "                                   selected_fields, \n",
    "                                   batch_size=global_batch_size)\n",
    "    training_ds = get_bq_dataset(FLAGS.training_table,\n",
    "                                 selected_fields,\n",
    "                                 batch_size=global_batch_size)\n",
    "    \n",
    "    testing_ds = get_bq_dataset(FLAGS.testing_table,\n",
    "                                selected_fields,\n",
    "                                batch_size=global_batch_size)\n",
    "    \n",
    "    # Prepare the model\n",
    "    input_features = {key: value for key, value in FEATURES.items() if key != TARGET_FEATURE_NAME}\n",
    "    logging.info('Creating the model ...')\n",
    "    \n",
    "    with strategy.scope():\n",
    "        model = create_model(training_ds, input_features, FLAGS.units, FLAGS.dropout_ratio)\n",
    "        model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Configure Keras callbacks\n",
    "    model_dir, tb_dir, checkpoint_dir = set_job_dirs()\n",
    "    callbacks = [tf.keras.callbacks.experimental.BackupAndRestore(backup_dir=checkpoint_dir)]\n",
    "    callbacks.append(tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=tb_dir, update_freq='batch'))\n",
    "    \n",
    "    logging.info('Starting training ...')\n",
    "    model.fit(training_ds, \n",
    "              epochs=FLAGS.epochs, \n",
    "              validation_data=validation_ds,\n",
    "              callbacks=callbacks)\n",
    "    \n",
    "    results = model.evaluate(testing_ds, return_dict=True)\n",
    "    tf.io.write_file(\n",
    "        f'{model_dir}/{EVALUATION_FILE_NAME}',\n",
    "        json.dumps(results)\n",
    "    )\n",
    "\n",
    "    # Save trained model\n",
    "    logging.info('Training completed. Saving the trained model to: {}'.format(model_dir))\n",
    "    model.save(model_dir)  \n",
    "    \n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    logging.set_verbosity(logging.INFO)\n",
    "    app.run(main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd10e1e4",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e9d1af47",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade73f29",
   "metadata": {},
   "source": [
    "### Create or set Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2dccc9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing Tensorboard: projects/895222332033/locations/us-central1/tensorboards/7964545572260544512\n"
     ]
    }
   ],
   "source": [
    "tb_client = api_client = vertex_ai.initializer.global_config.create_client(\n",
    "        client_class=vertex_ai.utils.TensorboardClientWithOverride, location_override=REGION\n",
    ")\n",
    "parent = f'projects/{PROJECT}/locations/{REGION}'\n",
    "\n",
    "tensorboard_display_name = 'Workshop Tensorboard'\n",
    "tensorboard_ref = None\n",
    "\n",
    "for tensorboard in tb_client.list_tensorboards(parent=parent):\n",
    "    if tensorboard.display_name == tensorboard_display_name:\n",
    "        tensorboard_ref = tensorboard\n",
    "        \n",
    "if not tensorboard_ref:\n",
    "    print('Creating new Tensorboard')\n",
    "    tb_specs = types.Tensorboard(\n",
    "        display_name=tensorboard_display_name,\n",
    "        description=tensorboard_display_name\n",
    "    )\n",
    "    operation = tb_client.create_tensorboard(parent=parent, tensorboard=tb_specs)\n",
    "    tensorboard_ref = operation.result()\n",
    "else:\n",
    "    print('Using existing Tensorboard:', tensorboard_ref.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c626b0c5",
   "metadata": {},
   "source": [
    "### Configure and submit a custom Vertex job using a script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cea1f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.source_utils:Training script copied to:\n",
      "gs://jk-vertex-workshop-bucket/JOB_20210608_132512/aiplatform-2021-06-08-13:25:12.815-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/8357981619004375040\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/8357981619004375040')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8357981619004375040?project=895222332033\n"
     ]
    }
   ],
   "source": [
    "job_name = job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = f'{STAGING_BUCKET}/jobs/{job_name}'\n",
    "\n",
    "container_uri = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "requirements = ['tensorflow-datasets==4.3.0']\n",
    "args = [\n",
    "    '--epochs=3', \n",
    "    '--per_replica_batch_size=128',\n",
    "    '--training_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TRAIN_SPLIT_NAME}',\n",
    "    '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TRAIN_SPLIT_NAME}',\n",
    "    '--testing_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TEST_SPLIT_NAME}',\n",
    "]\n",
    "\n",
    "machine_type = 'n1-standard-4'\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "accelerator_count = 1\n",
    "\n",
    "job = vertex_ai.CustomJob.from_local_script(\n",
    "    display_name=job_name,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    script_path='trainer/train.py',\n",
    "    container_uri=container_uri,\n",
    "    requirements=requirements,\n",
    "    args=args,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{job_name}'\n",
    ")\n",
    "\n",
    "job.run(sync=False, \n",
    "        service_account=VERTEX_SA,\n",
    "        tensorboard=tensorboard_ref.name,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473db99",
   "metadata": {},
   "source": [
    "### Configure and submit a Vertex job using a custom container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ded2f2",
   "metadata": {},
   "source": [
    "#### Create a docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6fefb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8357981619004375040 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8357981619004375040 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8357981619004375040 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-5'\n",
    "TRAIN_IMAGE = f'gcr.io/{PROJECT}/taxi_classifier_trainer'\n",
    "\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\"]\n",
    "CMD [\"-c\", \"print('Hello')\"]\n",
    "'''\n",
    "\n",
    "with open(os.path.join(SCRIPT_FOLDER, 'Dockerfile'), 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de45123",
   "metadata": {},
   "source": [
    "#### Build a container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16ee0e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 2 file(s) totalling 7.6 KiB before compression.\n",
      "Uploading tarball of [trainer] to [gs://jk-mlops-dev_cloudbuild/source/1623134389.357049-e796f257c8e64292828aa768927fd735.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jk-mlops-dev/locations/global/builds/df9bbefb-a351-4cbe-afc2-0c7ac2af991f].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/df9bbefb-a351-4cbe-afc2-0c7ac2af991f?project=895222332033].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"df9bbefb-a351-4cbe-afc2-0c7ac2af991f\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jk-mlops-dev_cloudbuild/source/1623134389.357049-e796f257c8e64292828aa768927fd735.tgz#1623134389644019\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5971073816498012160 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "Copying gs://jk-mlops-dev_cloudbuild/source/1623134389.357049-e796f257c8e64292828aa768927fd735.tgz#1623134389644019...\n",
      "/ [1 files][  2.8 KiB/  2.8 KiB]                                                \n",
      "Operation completed over 1 objects/2.8 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  10.24kB\n",
      "Step 1/5 : FROM gcr.io/deeplearning-platform-release/tf2-gpu.2-5\n",
      "latest: Pulling from deeplearning-platform-release/tf2-gpu.2-5\n",
      "6e0aa5e7af40: Pulling fs layer\n",
      "d47239a868b3: Pulling fs layer\n",
      "49cbb10cca85: Pulling fs layer\n",
      "4450dd082e0f: Pulling fs layer\n",
      "2c645f69b1d6: Pulling fs layer\n",
      "c51f99ae46a1: Pulling fs layer\n",
      "ece22f1f3a5c: Pulling fs layer\n",
      "0ecbf0b7bbf8: Pulling fs layer\n",
      "5848f1cb3b81: Pulling fs layer\n",
      "2f54b1f16acd: Pulling fs layer\n",
      "16e84ce81d85: Pulling fs layer\n",
      "c8e5550a4fa4: Pulling fs layer\n",
      "2e3325ceca25: Pulling fs layer\n",
      "184fc506e44a: Pulling fs layer\n",
      "4c311d4b2a10: Pulling fs layer\n",
      "116fdb019315: Pulling fs layer\n",
      "aeff92ad872e: Pulling fs layer\n",
      "c9952ed3db5f: Pulling fs layer\n",
      "fb3902b5a3a7: Pulling fs layer\n",
      "1f8b60f00749: Pulling fs layer\n",
      "d3ab4706459e: Pulling fs layer\n",
      "341ba8f946a1: Pulling fs layer\n",
      "79a0842bd8ff: Pulling fs layer\n",
      "e124988c5196: Pulling fs layer\n",
      "066a3d03cb12: Pulling fs layer\n",
      "cd55345c1107: Pulling fs layer\n",
      "4b14047dd86b: Pulling fs layer\n",
      "2e6bc3c78abb: Pulling fs layer\n",
      "ec905b2f50fb: Pulling fs layer\n",
      "bebe0539490e: Pulling fs layer\n",
      "cc5c7d8065a0: Pulling fs layer\n",
      "2e23073eebf2: Pulling fs layer\n",
      "16e84ce81d85: Waiting\n",
      "c8e5550a4fa4: Waiting\n",
      "2e3325ceca25: Waiting\n",
      "184fc506e44a: Waiting\n",
      "4c311d4b2a10: Waiting\n",
      "116fdb019315: Waiting\n",
      "aeff92ad872e: Waiting\n",
      "c9952ed3db5f: Waiting\n",
      "fb3902b5a3a7: Waiting\n",
      "1f8b60f00749: Waiting\n",
      "d3ab4706459e: Waiting\n",
      "341ba8f946a1: Waiting\n",
      "79a0842bd8ff: Waiting\n",
      "e124988c5196: Waiting\n",
      "066a3d03cb12: Waiting\n",
      "cd55345c1107: Waiting\n",
      "4b14047dd86b: Waiting\n",
      "2e6bc3c78abb: Waiting\n",
      "ec905b2f50fb: Waiting\n",
      "bebe0539490e: Waiting\n",
      "cc5c7d8065a0: Waiting\n",
      "2e23073eebf2: Waiting\n",
      "4450dd082e0f: Waiting\n",
      "2c645f69b1d6: Waiting\n",
      "c51f99ae46a1: Waiting\n",
      "ece22f1f3a5c: Waiting\n",
      "0ecbf0b7bbf8: Waiting\n",
      "5848f1cb3b81: Waiting\n",
      "2f54b1f16acd: Waiting\n",
      "49cbb10cca85: Verifying Checksum\n",
      "49cbb10cca85: Download complete\n",
      "d47239a868b3: Verifying Checksum\n",
      "d47239a868b3: Download complete\n",
      "4450dd082e0f: Verifying Checksum\n",
      "4450dd082e0f: Download complete\n",
      "2c645f69b1d6: Verifying Checksum\n",
      "2c645f69b1d6: Download complete\n",
      "6e0aa5e7af40: Verifying Checksum\n",
      "6e0aa5e7af40: Download complete\n",
      "c51f99ae46a1: Verifying Checksum\n",
      "c51f99ae46a1: Download complete\n",
      "ece22f1f3a5c: Verifying Checksum\n",
      "ece22f1f3a5c: Download complete\n",
      "5848f1cb3b81: Verifying Checksum\n",
      "5848f1cb3b81: Download complete\n",
      "16e84ce81d85: Verifying Checksum\n",
      "16e84ce81d85: Download complete\n",
      "6e0aa5e7af40: Pull complete\n",
      "d47239a868b3: Pull complete\n",
      "49cbb10cca85: Pull complete\n",
      "4450dd082e0f: Pull complete\n",
      "2c645f69b1d6: Pull complete\n",
      "c51f99ae46a1: Pull complete\n",
      "ece22f1f3a5c: Pull complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5971073816498012160 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "2f54b1f16acd: Verifying Checksum\n",
      "2f54b1f16acd: Download complete\n",
      "2e3325ceca25: Verifying Checksum\n",
      "2e3325ceca25: Download complete\n",
      "c8e5550a4fa4: Verifying Checksum\n",
      "c8e5550a4fa4: Download complete\n",
      "0ecbf0b7bbf8: Verifying Checksum\n",
      "0ecbf0b7bbf8: Download complete\n",
      "184fc506e44a: Verifying Checksum\n",
      "184fc506e44a: Download complete\n",
      "116fdb019315: Verifying Checksum\n",
      "116fdb019315: Download complete\n",
      "aeff92ad872e: Verifying Checksum\n",
      "aeff92ad872e: Download complete\n",
      "fb3902b5a3a7: Verifying Checksum\n",
      "fb3902b5a3a7: Download complete\n",
      "4c311d4b2a10: Verifying Checksum\n",
      "4c311d4b2a10: Download complete\n",
      "1f8b60f00749: Verifying Checksum\n",
      "1f8b60f00749: Download complete\n",
      "d3ab4706459e: Verifying Checksum\n",
      "d3ab4706459e: Download complete\n",
      "341ba8f946a1: Verifying Checksum\n",
      "341ba8f946a1: Download complete\n",
      "79a0842bd8ff: Verifying Checksum\n",
      "79a0842bd8ff: Download complete\n",
      "066a3d03cb12: Verifying Checksum\n",
      "066a3d03cb12: Download complete\n",
      "e124988c5196: Verifying Checksum\n",
      "e124988c5196: Download complete\n",
      "cd55345c1107: Verifying Checksum\n",
      "cd55345c1107: Download complete\n",
      "c9952ed3db5f: Verifying Checksum\n",
      "c9952ed3db5f: Download complete\n",
      "4b14047dd86b: Verifying Checksum\n",
      "4b14047dd86b: Download complete\n",
      "ec905b2f50fb: Verifying Checksum\n",
      "ec905b2f50fb: Download complete\n",
      "cc5c7d8065a0: Verifying Checksum\n",
      "cc5c7d8065a0: Download complete\n",
      "2e23073eebf2: Verifying Checksum\n",
      "2e23073eebf2: Download complete\n",
      "bebe0539490e: Verifying Checksum\n",
      "bebe0539490e: Download complete\n",
      "2e6bc3c78abb: Verifying Checksum\n",
      "2e6bc3c78abb: Download complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5971073816498012160 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "0ecbf0b7bbf8: Pull complete\n",
      "5848f1cb3b81: Pull complete\n",
      "2f54b1f16acd: Pull complete\n",
      "16e84ce81d85: Pull complete\n",
      "c8e5550a4fa4: Pull complete\n",
      "2e3325ceca25: Pull complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5971073816498012160 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "184fc506e44a: Pull complete\n",
      "4c311d4b2a10: Pull complete\n",
      "116fdb019315: Pull complete\n",
      "aeff92ad872e: Pull complete\n",
      "c9952ed3db5f: Pull complete\n",
      "fb3902b5a3a7: Pull complete\n",
      "1f8b60f00749: Pull complete\n",
      "d3ab4706459e: Pull complete\n",
      "341ba8f946a1: Pull complete\n",
      "79a0842bd8ff: Pull complete\n",
      "e124988c5196: Pull complete\n",
      "066a3d03cb12: Pull complete\n",
      "cd55345c1107: Pull complete\n",
      "4b14047dd86b: Pull complete\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5971073816498012160 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "2e6bc3c78abb: Pull complete\n",
      "ec905b2f50fb: Pull complete\n",
      "bebe0539490e: Pull complete\n",
      "cc5c7d8065a0: Pull complete\n",
      "2e23073eebf2: Pull complete\n",
      "Digest: sha256:d04d79d10f652dd4333d50e077cb736e19416f6aa334f9ee823a5a0b201fd92b\n",
      "Status: Downloaded newer image for gcr.io/deeplearning-platform-release/tf2-gpu.2-5:latest\n",
      " ---> 950969e5619c\n",
      "Step 2/5 : WORKDIR /trainer\n",
      " ---> Running in 98a0cec24590\n",
      "Removing intermediate container 98a0cec24590\n",
      " ---> 267a7294be38\n",
      "Step 3/5 : COPY train.py .\n",
      " ---> b2461fcb2afd\n",
      "Step 4/5 : ENTRYPOINT [\"python\"]\n",
      " ---> Running in e05daa30cad1\n",
      "Removing intermediate container e05daa30cad1\n",
      " ---> f2729263a3ee\n",
      "Step 5/5 : CMD [\"-c\", \"print('Hello')\"]\n",
      " ---> Running in 43861004fd8f\n",
      "Removing intermediate container 43861004fd8f\n",
      " ---> c7f21dc6c5a3\n",
      "Successfully built c7f21dc6c5a3\n",
      "Successfully tagged gcr.io/jk-mlops-dev/taxi_classifier_trainer:latest\n",
      "PUSH\n",
      "Pushing gcr.io/jk-mlops-dev/taxi_classifier_trainer\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/taxi_classifier_trainer]\n",
      "a9c68b6318c0: Preparing\n",
      "c703c1ed8501: Preparing\n",
      "5bfc464d3f17: Preparing\n",
      "006edaea14d2: Preparing\n",
      "622db28de254: Preparing\n",
      "e97052e30556: Preparing\n",
      "35c8fc085027: Preparing\n",
      "43677d90a58d: Preparing\n",
      "db84285b3362: Preparing\n",
      "786c0730cb59: Preparing\n",
      "a27f18de1f93: Preparing\n",
      "fca7d1dfb5d0: Preparing\n",
      "058d686f5924: Preparing\n",
      "90f85de2196f: Preparing\n",
      "801e383a0e80: Preparing\n",
      "1c86eaf882b2: Preparing\n",
      "b24d2519572d: Preparing\n",
      "160dfbfba824: Preparing\n",
      "efaea8806df6: Preparing\n",
      "36292a1c8291: Preparing\n",
      "d569b49af22b: Preparing\n",
      "186cb363f69f: Preparing\n",
      "d5de0a9a6a11: Preparing\n",
      "75867e8b38e6: Preparing\n",
      "edb28f196cf4: Preparing\n",
      "463a01dbc7de: Preparing\n",
      "716331d2d72b: Preparing\n",
      "c79fa966f459: Preparing\n",
      "64d8b9e63cdf: Preparing\n",
      "988749f5bf51: Preparing\n",
      "2d4faa2fa9fe: Preparing\n",
      "6f15325cc380: Preparing\n",
      "1e77dd81f9fa: Preparing\n",
      "030309cad0ba: Preparing\n",
      "e97052e30556: Waiting\n",
      "35c8fc085027: Waiting\n",
      "43677d90a58d: Waiting\n",
      "db84285b3362: Waiting\n",
      "786c0730cb59: Waiting\n",
      "a27f18de1f93: Waiting\n",
      "fca7d1dfb5d0: Waiting\n",
      "058d686f5924: Waiting\n",
      "90f85de2196f: Waiting\n",
      "801e383a0e80: Waiting\n",
      "1c86eaf882b2: Waiting\n",
      "b24d2519572d: Waiting\n",
      "160dfbfba824: Waiting\n",
      "efaea8806df6: Waiting\n",
      "36292a1c8291: Waiting\n",
      "d569b49af22b: Waiting\n",
      "186cb363f69f: Waiting\n",
      "d5de0a9a6a11: Waiting\n",
      "75867e8b38e6: Waiting\n",
      "edb28f196cf4: Waiting\n",
      "463a01dbc7de: Waiting\n",
      "716331d2d72b: Waiting\n",
      "c79fa966f459: Waiting\n",
      "64d8b9e63cdf: Waiting\n",
      "988749f5bf51: Waiting\n",
      "2d4faa2fa9fe: Waiting\n",
      "6f15325cc380: Waiting\n",
      "1e77dd81f9fa: Waiting\n",
      "030309cad0ba: Waiting\n",
      "006edaea14d2: Layer already exists\n",
      "622db28de254: Layer already exists\n",
      "5bfc464d3f17: Layer already exists\n",
      "35c8fc085027: Layer already exists\n",
      "e97052e30556: Layer already exists\n",
      "43677d90a58d: Layer already exists\n",
      "db84285b3362: Layer already exists\n",
      "786c0730cb59: Layer already exists\n",
      "a27f18de1f93: Layer already exists\n",
      "fca7d1dfb5d0: Layer already exists\n",
      "058d686f5924: Layer already exists\n",
      "90f85de2196f: Layer already exists\n",
      "801e383a0e80: Layer already exists\n",
      "1c86eaf882b2: Layer already exists\n",
      "b24d2519572d: Layer already exists\n",
      "160dfbfba824: Layer already exists\n",
      "efaea8806df6: Layer already exists\n",
      "d569b49af22b: Layer already exists\n",
      "36292a1c8291: Layer already exists\n",
      "186cb363f69f: Layer already exists\n",
      "d5de0a9a6a11: Layer already exists\n",
      "75867e8b38e6: Layer already exists\n",
      "edb28f196cf4: Layer already exists\n",
      "463a01dbc7de: Layer already exists\n",
      "716331d2d72b: Layer already exists\n",
      "c79fa966f459: Layer already exists\n",
      "64d8b9e63cdf: Layer already exists\n",
      "988749f5bf51: Layer already exists\n",
      "2d4faa2fa9fe: Layer already exists\n",
      "1e77dd81f9fa: Layer already exists\n",
      "6f15325cc380: Layer already exists\n",
      "030309cad0ba: Layer already exists\n",
      "a9c68b6318c0: Pushed\n",
      "c703c1ed8501: Pushed\n",
      "latest: digest: sha256:1b72bb488db154e550af776e2c567ba78ad51ce70a9ce2bc2cdd667d06204c13 size: 7455\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                      IMAGES                                                 STATUS\n",
      "df9bbefb-a351-4cbe-afc2-0c7ac2af991f  2021-06-08T06:39:49+00:00  6M30S     gs://jk-mlops-dev_cloudbuild/source/1623134389.357049-e796f257c8e64292828aa768927fd735.tgz  gcr.io/jk-mlops-dev/taxi_classifier_trainer (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --tag {TRAIN_IMAGE} {SCRIPT_FOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2695921d",
   "metadata": {},
   "source": [
    "#### Prepare worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2cb7e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_IMAGE,\n",
    "            \"command\": [\"python\", \"train.py\"],\n",
    "            \"args\": [\n",
    "                '--epochs=2', \n",
    "                '--per_replica_batch_size=128',\n",
    "                '--training_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TRAIN_SPLIT_NAME}',\n",
    "                '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_VALID_SPLIT_NAME}',\n",
    "                '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TEST_SPLIT_NAME}',\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778d81c7",
   "metadata": {},
   "source": [
    "#### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7edb4405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/7105980922595377152\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/7105980922595377152')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/7105980922595377152?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7105980922595377152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8357981619004375040 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7105980922595377152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7105980922595377152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7105980922595377152 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8357981619004375040 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7105980922595377152 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "job_name = \"JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=f'{STAGING_BUCKET}/{job_name}'\n",
    ")\n",
    "\n",
    "job.run(sync=False, \n",
    "        service_account=VERTEX_SA,\n",
    "        tensorboard=tensorboard_ref.name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565cafdf",
   "metadata": {},
   "source": [
    "### Configure and submit a hyperparameter job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa65f7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/152423097935331328\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/152423097935331328')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/152423097935331328?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/152423097935331328 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/152423097935331328 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/152423097935331328 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/152423097935331328 current state:\n",
      "JobState.JOB_STATE_PENDING\n"
     ]
    }
   ],
   "source": [
    "job_name = \"HYPER_JOB_{}\".format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "hyperparameter_tuning_job_spec = {\n",
    "        \"display_name\": job_name,\n",
    "        \"max_trial_count\": 6,\n",
    "        \"parallel_trial_count\": 2,\n",
    "        \"max_failed_trial_count\": 1,\n",
    "        \"study_spec\": {\n",
    "            \"metrics\": [\n",
    "                {\n",
    "                    \"metric_id\": \"accuracy\",\n",
    "                    \"goal\": vertex_ai.gapic.StudySpec.MetricSpec.GoalType.MAXIMIZE,\n",
    "                }\n",
    "            ],\n",
    "            \"parameters\": [\n",
    "                {\n",
    "                    \"parameter_id\": \"units\",\n",
    "                    \"discrete_value_spec\": {\"values\": [32, 64]},\n",
    "                },\n",
    "                {\n",
    "                    \"parameter_id\": \"dropout_ratio\",\n",
    "                    \"double_value_spec\": {\"min_value\": 0.4, \"max_value\": 0.6},\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "        \"trial_job_spec\": {\n",
    "            \"base_output_directory\": {\n",
    "                \"output_uri_prefix\": f\"{STAGING_BUCKET}/{job_name}\"\n",
    "            },\n",
    "            \"worker_pool_specs\": [\n",
    "                {\n",
    "                    \"machine_spec\": {\n",
    "                        \"machine_type\": \"n1-standard-4\",\n",
    "                        \"accelerator_type\": vertex_ai.gapic.AcceleratorType.NVIDIA_TESLA_T4,\n",
    "                        \"accelerator_count\": 1,\n",
    "                    },\n",
    "                    \"replica_count\": 1,\n",
    "                    \"container_spec\": {\n",
    "                        \"image_uri\": TRAIN_IMAGE,\n",
    "                        \"command\": [\"python\", \"train.py\"],\n",
    "                        \"args\": [\n",
    "                            '--epochs=2', \n",
    "                            '--per_replica_batch_size=128',\n",
    "                            '--training_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TRAIN_SPLIT_NAME}',\n",
    "                            '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_VALID_SPLIT_NAME}',\n",
    "                            '--validation_table=' + f'{PROJECT}.{BQ_DATASET_NAME}.{BQ_TEST_SPLIT_NAME}',\n",
    "                        ],\n",
    "                    },\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_client = api_client = vertex_ai.initializer.global_config.create_client(\n",
    "        client_class=JobClientWithOverride, location_override=REGION\n",
    ")\n",
    "\n",
    "parent = f'projects/{PROJECT}/locations/{REGION}'\n",
    "\n",
    "response = job_client.create_hyperparameter_tuning_job(\n",
    "    parent=parent, hyperparameter_tuning_job=hyperparameter_tuning_job_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf362e",
   "metadata": {},
   "source": [
    "### Monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b6798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_spec = job_client.get_hyperparameter_tuning_job(\n",
    "    name = response.name\n",
    ")\n",
    "print(job_spec.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80131add",
   "metadata": {},
   "source": [
    "## Deploying a model to Vertex "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cad847",
   "metadata": {},
   "source": [
    "### Inspect the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb624b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = 'gs://jk-vertex-workshop-bucket/models/taxi'\n",
    "\n",
    "!saved_model_cli show --dir {saved_model_path} --tag_set serve --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcb4864",
   "metadata": {},
   "source": [
    "### Upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7fec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = 'Chicago taxi tip classifier'\n",
    "description = 'Chicago taxi tip TensorFlow classifier'\n",
    "serving_image_uri = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-4:latest'\n",
    "\n",
    "model = vertex_ai.Model.upload(\n",
    "    display_name=display_name,\n",
    "    description=description,\n",
    "    artifact_uri=saved_model_path,\n",
    "    serving_container_image_uri=serving_image_uri\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1697592d",
   "metadata": {},
   "source": [
    "### Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29fbb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_name = 'Taxi tip classifier endpoint'\n",
    "\n",
    "endpoint = vertex_ai.Endpoint.create(display_name=display_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf18f7",
   "metadata": {},
   "source": [
    "### Deploy the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96d44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployed_model_display_name = 'taxi-v1'\n",
    "traffic_percentage = 100\n",
    "machine_type = 'n1-standard-4'\n",
    "\n",
    "endpoint = model.deploy(\n",
    "        endpoint=endpoint,\n",
    "        deployed_model_display_name=deployed_model_display_name,\n",
    "        machine_type=machine_type,\n",
    "        traffic_percentage=traffic_percentage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5cfc76",
   "metadata": {},
   "source": [
    "## Invoking the deployed model using Vertex SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0119dbde",
   "metadata": {},
   "source": [
    "### Get the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e028f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for endpoint_info in vertex_ai.Endpoint.list(filter='display_name=\"Taxi tip classifier endpoint\"'):\n",
    "    print(endpoint_info)\n",
    "    \n",
    "endpoint = vertex_ai.Endpoint(endpoint_info.resource_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f2123a",
   "metadata": {},
   "source": [
    "### Call the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7ab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_instances = [  \n",
    "    \n",
    "    {\n",
    "        \"dropoff_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"euclidean\": [2064.2696],\n",
    "        \"payment_type\": [\"Credit Card\"],\n",
    "        \"pickup_grid\": [\"POINT(-87.6 41.9)\"],\n",
    "        \"trip_miles\": [1.37],\n",
    "        \"trip_day\": [12],\n",
    "        \"trip_hour\": [16],\n",
    "        \"trip_month\": [2],\n",
    "        \"trip_day_of_week\": [4],\n",
    "        \"trip_seconds\": [555]\n",
    "    }\n",
    "]\n",
    "\n",
    "predictions = endpoint.predict(instances=test_instances)\n",
    "prob = tf.nn.sigmoid(predictions[0])\n",
    "print('Probability of tip > 20%:', prob.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f427179",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8fd4f7",
   "metadata": {},
   "source": [
    "### Undeploy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecacf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.list_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280cc8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.undeploy_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea81232",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c5371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7763646",
   "metadata": {},
   "source": [
    "### Delete model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61198d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66117475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-4.m69",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-4:m69"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
